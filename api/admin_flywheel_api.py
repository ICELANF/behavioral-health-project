"""
Admin é£è½® API â€” æŒ‡æŒ¥ä¸­å¿ƒ Dashboard (Real DB)
ç«¯ç‚¹ (12ä¸ª):
  GET  /api/v1/admin/kpi/realtime           â†’ 4å¤§æ ¸å¿ƒKPI
  GET  /api/v1/admin/channels/health        â†’ æ¸ é“å¥åº·
  GET  /api/v1/admin/funnel                 â†’ è½¬åŒ–æ¼æ–—
  GET  /api/v1/admin/agents/monitor         â†’ 33AgentçŠ¶æ€
  GET  /api/v1/admin/agents/performance     â†’ Agent P95æ’è¡Œ
  GET  /api/v1/admin/coaches/ranking        â†’ æ•™ç»ƒæ•ˆç‡æ’è¡Œ
  GET  /api/v1/admin/safety/24h             â†’ å®‰å…¨çº¢çº¿S1-S6
  GET  /api/v1/admin/alerts/active          â†’ æ´»è·ƒå‘Šè­¦
  POST /api/v1/admin/alerts/:id/dismiss     â†’ å…³é—­å‘Šè­¦
  GET  /api/v1/admin/users/overview         â†’ ç”¨æˆ·æ€»è§ˆ
  GET  /api/v1/admin/system/containers      â†’ å®¹å™¨çŠ¶æ€
  GET  /api/v1/admin/audit-log/recent       â†’ æœ€è¿‘å®¡è®¡æ—¥å¿—
"""

import logging
from datetime import date, datetime, timedelta
from typing import Optional, Literal

from fastapi import APIRouter, Depends, HTTPException, Path
from pydantic import BaseModel
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from core.database import get_async_db
from api.dependencies import require_admin

logger = logging.getLogger("admin_flywheel")

router = APIRouter(prefix="/api/v1/admin", tags=["admin-flywheel"])


def _relative_time(dt: datetime) -> str:
    """Format datetime as relative time string (Chinese)."""
    delta = datetime.utcnow() - dt
    secs = delta.total_seconds()
    if secs < 0:
        return "åˆšåˆš"
    if secs < 60:
        return "åˆšåˆš"
    if secs < 3600:
        return f"{int(secs / 60)}åˆ†é’Ÿå‰"
    if secs < 86400:
        return f"{int(secs / 3600)}å°æ—¶å‰"
    return f"{delta.days}å¤©å‰"


def _fmt_count(n: int) -> str:
    """Format integer with comma separators."""
    return f"{n:,}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Schema
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class CoreKPI(BaseModel):
    icon: str
    value: str
    label: str
    sub: str
    trend_dir: Literal["up", "down", "flat"]
    trend_pct: float
    status: Literal["good", "warn", "critical"]


class ChannelHealth(BaseModel):
    icon: str
    name: str
    status: Literal["healthy", "degraded", "down"]
    status_label: str
    dau: str
    msg_today: str
    avg_reply: str
    error_rate: float = 0.0


class FunnelStep(BaseModel):
    label: str
    count: str
    pct: float
    color: str
    conv_rate: Optional[str] = None


class AgentStatus(BaseModel):
    id: str
    name: str
    layer: str          # ç”¨æˆ·å±‚|æ•™ç»ƒå±‚|ç³»ç»Ÿå±‚|ä¸­åŒ»éª¨ç§‘
    status: Literal["ok", "slow", "error", "offline"]
    status_label: str
    p95_ms: Optional[int] = None
    calls_today: int = 0
    error_rate: float = 0.0


class AgentPerf(BaseModel):
    name: str
    agent_id: str
    p95: int            # P95å»¶è¿Ÿ(ms)
    avg: int
    calls: int


class CoachRank(BaseModel):
    name: str
    coach_id: int
    students: int
    today_reviewed: int
    avg_seconds: int
    approval_rate: float


class SafetyMetric(BaseModel):
    rule: str           # S1-S6
    label: str
    count: int          # 24hè§¦å‘æ¬¡æ•°
    last_triggered: Optional[str] = None


class Alert(BaseModel):
    id: str
    level: Literal["critical", "warning", "info"]
    message: str
    source: str
    time: str
    auto_resolved: bool = False


class AlertDismissResponse(BaseModel):
    success: bool
    alert_id: str


class UserOverview(BaseModel):
    total_users: int
    by_role: dict[str, int]     # {Observer: N, Grower: N, ...}
    by_stage: dict[str, int]    # {S0: N, S1: N, ...}
    new_today: int
    active_today: int


class ContainerStatus(BaseModel):
    name: str
    port: str
    status: Literal["running", "stopped", "error"]
    uptime: str
    cpu_pct: float
    mem_mb: int


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Agent reference list (used when agent_templates table is empty/missing)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_AGENT_SEED = {
    "ç”¨æˆ·å±‚": [
        ("health_assistant", "å¥åº·åŠ©æ‰‹"), ("crisis_responder", "å±æœºå“åº”"),
        ("onboarding_guide", "å¼•å¯¼å‘å¯¼"), ("nutrition_guide", "è¥å…»æŒ‡å¯¼"),
        ("exercise_guide", "è¿åŠ¨æŒ‡å¯¼"), ("sleep_guide", "ç¡çœ æŒ‡å¯¼"),
        ("emotion_support", "æƒ…ç»ªæ”¯æŒ"), ("tcm_wellness", "ä¸­åŒ»å…»ç”Ÿ"),
        ("motivation_support", "åŠ¨æœºæ”¯æŒ"), ("habit_tracker", "ä¹ æƒ¯è¿½è¸ª"),
        ("community_guide", "åŒé“è€…å¼•å¯¼"), ("content_recommender", "å†…å®¹æ¨è"),
        ("pain_relief_guide", "ç–¼ç—›ç¼“è§£"), ("rehab_exercise_guide", "åº·å¤è¿åŠ¨"),
    ],
    "æ•™ç»ƒå±‚": [
        ("behavior_coach", "è¡Œä¸ºæ•™ç»ƒ"), ("assessment_engine", "è¯„ä¼°å¼•æ“"),
        ("rx_composer", "å¤„æ–¹ç¼–å†™"), ("stage_tracker", "é˜¶æ®µè¿½è¸ª"),
        ("progress_analyzer", "è¿›åº¦åˆ†æ"), ("risk_detector", "é£é™©æ£€æµ‹"),
        ("quality_auditor", "è´¨é‡å®¡è®¡"), ("coach_advisor", "æ•™ç»ƒé¡¾é—®"),
        ("report_generator", "æŠ¥å‘Šç”Ÿæˆ"), ("binding_manager", "ç»‘å®šç®¡ç†"),
    ],
    "ç³»ç»Ÿå±‚": [
        ("scheduler_agent", "è°ƒåº¦Agent"), ("data_sync_agent", "æ•°æ®åŒæ­¥"),
        ("notification_agent", "é€šçŸ¥Agent"), ("audit_logger", "å®¡è®¡æ—¥å¿—"),
    ],
    "ä¸­åŒ»éª¨ç§‘": [
        ("tcm_ortho_expert", "ä¸­åŒ»éª¨ç§‘ä¸“å®¶"), ("pain_management_expert", "ç–¼ç—›ç®¡ç†ä¸“å®¶"),
        ("ortho_rehab_planner", "éª¨ç§‘åº·å¤è§„åˆ’"), ("tcm_exercise_guide", "ä¼ ç»ŸåŠŸæ³•æŒ‡å¯¼"),
        ("meridian_acupoint", "ç»ç»œç©´ä½"),
    ],
}

# Flat lookup: agent_id â†’ (display_name, layer)
_AGENT_LOOKUP: dict[str, tuple[str, str]] = {}
for _layer, _agents in _AGENT_SEED.items():
    for _aid, _aname in _agents:
        _AGENT_LOOKUP[_aid] = (_aname, _layer)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. GET /kpi/realtime
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/kpi/realtime", response_model=list[CoreKPI])
async def get_realtime_kpi(
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """4å¤§æ ¸å¿ƒKPI â€” 5sè½®è¯¢"""
    try:
        today = date.today()
        yesterday = today - timedelta(days=1)

        # KPI 1: DAU â€” distinct users with chat_messages today (via chat_sessions)
        r = await db.execute(text("""
            SELECT COUNT(DISTINCT cs.user_id)
            FROM chat_messages cm
            JOIN chat_sessions cs ON cs.id = cm.session_id
            WHERE cm.created_at >= :today
        """), {"today": today})
        dau_today = r.scalar() or 0

        r = await db.execute(text("""
            SELECT COUNT(DISTINCT cs.user_id)
            FROM chat_messages cm
            JOIN chat_sessions cs ON cs.id = cm.session_id
            WHERE cm.created_at >= :yesterday AND cm.created_at < :today
        """), {"yesterday": yesterday, "today": today})
        dau_yesterday = r.scalar() or 0

        dau_trend_pct = round((dau_today - dau_yesterday) / max(dau_yesterday, 1) * 100, 1)
        dau_dir = "up" if dau_trend_pct > 0 else ("down" if dau_trend_pct < 0 else "flat")

        # KPI 2: Observerâ†’Grower conversion rate
        r = await db.execute(text("""
            SELECT COUNT(*) FILTER (WHERE role::text != 'OBSERVER') as converted,
                   COUNT(*) as total
            FROM users WHERE is_active = true
        """))
        row = r.mappings().first()
        converted = row["converted"] if row else 0
        total_users = row["total"] if row else 1
        conv_rate = round(converted / max(total_users, 1) * 100, 1)

        # KPI 3: 7-day retention (grower+ with daily_tasks activity)
        seven_days_ago = today - timedelta(days=7)
        r = await db.execute(text("""
            SELECT COUNT(DISTINCT dt.user_id)
            FROM daily_tasks dt JOIN users u ON u.id = dt.user_id
            WHERE dt.task_date >= :seven_days_ago AND u.role::text != 'OBSERVER'
        """), {"seven_days_ago": seven_days_ago})
        active_growers_7d = r.scalar() or 0

        r = await db.execute(text(
            "SELECT COUNT(*) FROM users WHERE role::text != 'OBSERVER' AND is_active = true"
        ))
        total_growers = r.scalar() or 1
        retention_rate = round(active_growers_7d / max(total_growers, 1) * 100, 1)
        retention_status = "good" if retention_rate >= 70 else ("warn" if retention_rate >= 50 else "critical")

        # KPI 4: AI avg response time
        r = await db.execute(text("""
            SELECT COALESCE(AVG(latency_ms), 0)::int as avg_ms,
                   COALESCE(MAX(latency_ms), 0)::int as p95_approx
            FROM llm_call_logs
            WHERE created_at >= :today AND latency_ms > 0
        """), {"today": today})
        ai_row = r.mappings().first()
        avg_ms = ai_row["avg_ms"] if ai_row else 0
        p95_ms = ai_row["p95_approx"] if ai_row else 0
        avg_sec = round(avg_ms / 1000, 1) if avg_ms > 0 else 0.0
        p95_sec = round(p95_ms / 1000, 1) if p95_ms > 0 else 0.0
        ai_status = "good" if avg_ms < 3000 else ("warn" if avg_ms < 5000 else "critical")

        # Count timeout rate
        r = await db.execute(text("""
            SELECT COUNT(*) FILTER (WHERE latency_ms > 5000) as timeouts,
                   COUNT(*) as total
            FROM llm_call_logs WHERE created_at >= :today AND latency_ms > 0
        """), {"today": today})
        to_row = r.mappings().first()
        timeout_pct = round((to_row["timeouts"] or 0) / max(to_row["total"] or 1, 1) * 100, 1) if to_row else 0.0

        return [
            CoreKPI(
                icon="ğŸ‘¥", value=_fmt_count(dau_today), label="DAU (å…¨æ¸ é“)",
                sub=f"ä»Šæ—¥æ´»è·ƒç”¨æˆ·",
                trend_dir=dau_dir, trend_pct=abs(dau_trend_pct),
                status="good" if dau_today > 0 else "warn",
            ),
            CoreKPI(
                icon="ğŸ”„", value=f"{conv_rate}%", label="Observerâ†’Grower è½¬åŒ–",
                sub=f"å·²è½¬åŒ– {converted}/{total_users}",
                trend_dir="up" if conv_rate > 30 else "flat",
                trend_pct=conv_rate,
                status="good" if conv_rate > 25 else "warn",
            ),
            CoreKPI(
                icon="ğŸ“Š", value=f"{retention_rate}%", label="7æ—¥ç•™å­˜ç‡",
                sub=f"Grower+ æ´»è·ƒ {active_growers_7d}/{total_growers}",
                trend_dir="up" if retention_rate >= 70 else "down",
                trend_pct=retention_rate,
                status=retention_status,
            ),
            CoreKPI(
                icon="ğŸ¤–", value=f"{avg_sec}s", label="AIå¹³å‡å“åº”",
                sub=f"P95: {p95_sec}s Â· è¶…æ—¶ç‡: {timeout_pct}%",
                trend_dir="up" if avg_ms < 2000 else "down",
                trend_pct=round(avg_sec, 1),
                status=ai_status,
            ),
        ]
    except Exception as e:
        logger.warning("kpi/realtime fallback: %s", e)
        return [
            CoreKPI(icon="ğŸ‘¥", value="0", label="DAU (å…¨æ¸ é“)", sub="æ•°æ®åŠ è½½ä¸­", trend_dir="flat", trend_pct=0, status="warn"),
            CoreKPI(icon="ğŸ”„", value="0%", label="Observerâ†’Grower è½¬åŒ–", sub="æ•°æ®åŠ è½½ä¸­", trend_dir="flat", trend_pct=0, status="warn"),
            CoreKPI(icon="ğŸ“Š", value="0%", label="7æ—¥ç•™å­˜ç‡", sub="æ•°æ®åŠ è½½ä¸­", trend_dir="flat", trend_pct=0, status="warn"),
            CoreKPI(icon="ğŸ¤–", value="0s", label="AIå¹³å‡å“åº”", sub="æ•°æ®åŠ è½½ä¸­", trend_dir="flat", trend_pct=0, status="warn"),
        ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. GET /channels/health
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/channels/health", response_model=list[ChannelHealth])
async def get_channels_health(
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """æ¸ é“å¥åº· â€” 10sè½®è¯¢ (real metrics from activity logs)"""
    today_str = date.today().isoformat()
    try:
        # H5 DAU from activity logs
        h5_r = await db.execute(text(
            "SELECT COUNT(DISTINCT user_id) FROM user_activity_logs WHERE created_at::date = :d"
        ), {"d": today_str})
        h5_dau = h5_r.scalar() or 0

        # WeChat DAU (users with wx_openid + today's activity)
        wx_r = await db.execute(text("""
            SELECT COUNT(DISTINCT u.id) FROM users u
            JOIN user_activity_logs ual ON ual.user_id = u.id
            WHERE u.wx_openid IS NOT NULL AND ual.created_at::date = :d
        """), {"d": today_str})
        wx_dau = wx_r.scalar() or 0

        # Today's chat messages
        msg_r = await db.execute(text(
            "SELECT COUNT(*) FROM user_activity_logs WHERE created_at::date = :d AND activity_type IN ('chat', 'chat_message')"
        ), {"d": today_str})
        msg_today = msg_r.scalar() or 0

        # Error rate from llm_call_logs (if table exists)
        error_rate = 0.0
        try:
            err_r = await db.execute(text("""
                SELECT COUNT(*) FILTER (WHERE status = 'error')::float / GREATEST(COUNT(*), 1)
                FROM llm_call_logs WHERE created_at::date = :d
            """), {"d": today_str})
            error_rate = round(err_r.scalar() or 0.0, 4)
        except Exception:
            pass

    except Exception as e:
        logger.warning(f"channels/health query failed: {e}")
        h5_dau, wx_dau, msg_today, error_rate = 0, 0, 0, 0.0

    return [
        ChannelHealth(
            icon="ğŸ“±", name="H5 ç§»åŠ¨ç«¯", status="healthy", status_label="æ­£å¸¸",
            dau=str(h5_dau), msg_today=str(msg_today), avg_reply="--", error_rate=error_rate,
        ),
        ChannelHealth(
            icon="ğŸ’¬", name="å¾®ä¿¡æœåŠ¡å·",
            status="healthy" if wx_dau > 0 else "degraded",
            status_label="æ­£å¸¸" if wx_dau > 0 else "æœªæ¥å…¥",
            dau=str(wx_dau), msg_today="--", avg_reply="--",
        ),
        ChannelHealth(
            icon="ğŸŸ¢", name="å¾®ä¿¡å°ç¨‹åº", status="healthy", status_label="å¾…æ¥å…¥",
            dau="--", msg_today="--", avg_reply="--",
        ),
        ChannelHealth(
            icon="ğŸ‘”", name="ä¼ä¸šå¾®ä¿¡", status="healthy", status_label="å¾…æ¥å…¥",
            dau="--", msg_today="--", avg_reply="--",
        ),
    ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. GET /funnel
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/funnel", response_model=list[FunnelStep])
async def get_funnel(
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """è½¬åŒ–æ¼æ–— â€” 1håˆ·æ–°"""
    try:
        # Step 1+2+3: user counts by role
        r = await db.execute(text("""
            SELECT
              COUNT(*) as total,
              COUNT(*) FILTER (WHERE role::text = 'OBSERVER') as observers,
              COUNT(*) FILTER (WHERE role::text != 'OBSERVER') as upgraded
            FROM users WHERE is_active = true
        """))
        row = r.mappings().first()
        total = row["total"] if row else 0
        observers = row["observers"] if row else 0
        upgraded = row["upgraded"] if row else 0

        # Step 4: assessed users (try baps_results, fallback to 0)
        assessed = 0
        try:
            r = await db.execute(text("SELECT COUNT(DISTINCT user_id) FROM baps_results"))
            assessed = r.scalar() or 0
        except Exception:
            await db.rollback()

        # Step 5: 7-day active (grower+ with completed daily_tasks)
        r = await db.execute(text("""
            SELECT COUNT(DISTINCT user_id) FROM daily_tasks
            WHERE task_date >= CURRENT_DATE - 7 AND done = true
        """))
        active_7d = r.scalar() or 0

        # Build funnel â€” each step's pct is relative to total
        base = max(total, 1)
        steps = [
            ("æ³¨å†Œç”¨æˆ·", total, 100.0, "#93c5fd", None),
            ("Observer", observers, round(observers / base * 100, 1), "#60a5fa",
             f"{round(observers / base * 100, 1)}" if total else None),
            ("å®Œæˆè¯„ä¼°", assessed, round(assessed / base * 100, 1), "#3b82f6",
             f"{round(assessed / max(observers, 1) * 100, 1)}" if observers else None),
            ("å‡çº§Grower+", upgraded, round(upgraded / base * 100, 1), "#2563eb",
             f"{round(upgraded / max(assessed, 1) * 100, 1)}" if assessed else
             f"{round(upgraded / base * 100, 1)}"),
            ("7æ—¥æ´»è·ƒ", active_7d, round(active_7d / base * 100, 1), "#1d4ed8",
             f"{round(active_7d / max(upgraded, 1) * 100, 1)}" if upgraded else None),
        ]

        return [
            FunnelStep(label=lbl, count=_fmt_count(cnt), pct=pct, color=clr, conv_rate=cr)
            for lbl, cnt, pct, clr, cr in steps
        ]
    except Exception as e:
        logger.warning("funnel fallback: %s", e)
        return [
            FunnelStep(label="æ³¨å†Œç”¨æˆ·", count="0", pct=100, color="#93c5fd"),
            FunnelStep(label="Observer", count="0", pct=0, color="#60a5fa"),
            FunnelStep(label="å®Œæˆè¯„ä¼°", count="0", pct=0, color="#3b82f6"),
            FunnelStep(label="å‡çº§Grower+", count="0", pct=0, color="#2563eb"),
            FunnelStep(label="7æ—¥æ´»è·ƒ", count="0", pct=0, color="#1d4ed8"),
        ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. GET /agents/monitor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/agents/monitor", response_model=list[AgentStatus])
async def get_agents_monitor(
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """33AgentçŠ¶æ€ â€” 10sè½®è¯¢"""
    # Try to read from agent_templates + agent_metrics_daily;
    # fallback to hardcoded seed list if tables don't exist.
    metrics_map: dict[str, dict] = {}  # agent_id â†’ {total_calls, avg_ms}

    try:
        r = await db.execute(text("""
            SELECT agent_id, total_calls, avg_processing_ms::int as avg_ms
            FROM agent_metrics_daily WHERE metric_date = :today
        """), {"today": date.today()})
        for row in r.mappings():
            metrics_map[row["agent_id"]] = {
                "total_calls": row["total_calls"] or 0,
                "avg_ms": row["avg_ms"] or 0,
            }
    except Exception:
        pass  # table missing â€” use empty metrics

    # Also try LLM call logs as a secondary metric source
    try:
        r = await db.execute(text("""
            SELECT COALESCE(intent, 'unknown') as agent_id,
                   COUNT(*) as total_calls,
                   COALESCE(AVG(latency_ms), 0)::int as avg_ms
            FROM llm_call_logs
            WHERE created_at >= :today AND intent IS NOT NULL
            GROUP BY intent
        """), {"today": date.today()})
        for row in r.mappings():
            aid = row["agent_id"]
            if aid not in metrics_map:
                metrics_map[aid] = {
                    "total_calls": row["total_calls"] or 0,
                    "avg_ms": row["avg_ms"] or 0,
                }
    except Exception:
        pass

    # Build agent list from seed, overlay with real metrics
    agents = []
    for layer, agent_list in _AGENT_SEED.items():
        for aid, aname in agent_list:
            m = metrics_map.get(aid, {})
            calls = m.get("total_calls", 0)
            avg_ms = m.get("avg_ms", 0)

            if calls == 0 and avg_ms == 0:
                status, status_label = "offline", "ç¦»çº¿"
            elif avg_ms > 3000:
                status, status_label = "slow", "å“åº”æ…¢"
            else:
                status, status_label = "ok", "æ­£å¸¸"

            agents.append(AgentStatus(
                id=aid, name=aname, layer=layer,
                status=status, status_label=status_label,
                p95_ms=int(avg_ms * 1.5) if avg_ms > 0 else None,
                calls_today=calls,
            ))

    return agents


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. GET /agents/performance
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/agents/performance", response_model=list[AgentPerf])
async def get_agents_performance(
    top_n: int = 5,
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """Agent P95æ’è¡Œ â€” 1minåˆ·æ–°"""
    try:
        # Try agent_metrics_daily first
        rows = []
        try:
            r = await db.execute(text("""
                SELECT agent_id, avg_processing_ms::int as avg_ms, total_calls
                FROM agent_metrics_daily
                WHERE metric_date = :today AND total_calls > 0
                ORDER BY avg_processing_ms DESC LIMIT :top_n
            """), {"today": date.today(), "top_n": top_n})
            rows = list(r.mappings())
        except Exception:
            pass

        # Fallback to llm_call_logs
        if not rows:
            r = await db.execute(text("""
                SELECT COALESCE(intent, model_requested) as agent_id,
                       AVG(latency_ms)::int as avg_ms,
                       COUNT(*) as total_calls
                FROM llm_call_logs
                WHERE created_at >= :today AND latency_ms > 0
                GROUP BY 1
                HAVING COUNT(*) > 0
                ORDER BY avg_ms DESC LIMIT :top_n
            """), {"today": date.today(), "top_n": top_n})
            rows = list(r.mappings())

        result = []
        for row in rows:
            aid = row["agent_id"] or "unknown"
            avg_ms = row["avg_ms"] or 0
            calls = row["total_calls"] or 0
            display_name = _AGENT_LOOKUP.get(aid, (aid, ""))[0]
            result.append(AgentPerf(
                name=display_name, agent_id=aid,
                p95=int(avg_ms * 1.5), avg=avg_ms, calls=calls,
            ))
        return result
    except Exception as e:
        logger.warning("agents/performance fallback: %s", e)
        return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. GET /coaches/ranking
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/coaches/ranking", response_model=list[CoachRank])
async def get_coaches_ranking(
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """æ•™ç»ƒæ•ˆç‡æ’è¡Œ â€” 5minåˆ·æ–°"""
    try:
        today = date.today()
        r = await db.execute(text("""
            SELECT u.id, u.username,
              COUNT(DISTINCT q.student_id) as students,
              COUNT(*) FILTER (WHERE q.reviewed_at >= :today) as today_reviewed,
              COALESCE(
                AVG(l.elapsed_seconds) FILTER (WHERE l.reviewed_at >= :today),
                0
              )::int as avg_seconds,
              CASE WHEN COUNT(*) FILTER (WHERE q.status IN ('approved','rejected')) > 0
                THEN ROUND(
                  COUNT(*) FILTER (WHERE q.status='approved')::numeric /
                  COUNT(*) FILTER (WHERE q.status IN ('approved','rejected')),
                  2)
                ELSE 0.0
              END as approval_rate
            FROM users u
            LEFT JOIN coach_review_queue q ON q.coach_id = u.id
            LEFT JOIN coach_review_logs l ON l.coach_id = u.id
            WHERE u.role::text IN ('COACH','PROMOTER','SUPERVISOR','MASTER') AND u.is_active = true
            GROUP BY u.id, u.username
            ORDER BY today_reviewed DESC
        """), {"today": today})

        result = []
        for row in r.mappings():
            result.append(CoachRank(
                name=row["username"],
                coach_id=row["id"],
                students=row["students"] or 0,
                today_reviewed=row["today_reviewed"] or 0,
                avg_seconds=row["avg_seconds"] or 0,
                approval_rate=float(row["approval_rate"] or 0),
            ))
        return result
    except Exception as e:
        logger.warning("coaches/ranking fallback: %s", e)
        return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. GET /safety/24h
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_SAFETY_RULES = {
    "S1": "åŒ»ç–—è¾¹ç•Œ", "S2": "éšç§ä¿æŠ¤", "S3": "å±æœºæ£€æµ‹",
    "S4": "å†…å®¹åˆè§„", "S5": "æ•°æ®æœ€å°åŒ–", "S6": "å¾®ä¿¡åˆè§„",
}

# Map event_type patterns â†’ S-rule codes
_EVENT_TO_RULE = {
    "medical_boundary": "S1", "boundary_violation": "S1", "medication": "S1",
    "privacy": "S2", "pii_detected": "S2",
    "crisis": "S3", "suicide": "S3", "self_harm": "S3",
    "content_violation": "S4", "inappropriate": "S4",
    "data_minimization": "S5", "excessive_data": "S5",
    "wechat_compliance": "S6", "wechat": "S6",
}


@router.get("/safety/24h", response_model=list[SafetyMetric])
async def get_safety_24h(
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """å®‰å…¨çº¢çº¿S1-S6 24å°æ—¶è§¦å‘ç»Ÿè®¡ â€” 1minåˆ·æ–°"""
    try:
        r = await db.execute(text("""
            SELECT event_type, COUNT(*) as cnt, MAX(created_at) as last_triggered
            FROM safety_logs
            WHERE created_at >= NOW() - INTERVAL '24 hours'
            GROUP BY event_type
        """))

        # Aggregate by S-rule
        rule_counts: dict[str, int] = {k: 0 for k in _SAFETY_RULES}
        rule_last: dict[str, Optional[datetime]] = {k: None for k in _SAFETY_RULES}

        for row in r.mappings():
            et = (row["event_type"] or "").lower()
            cnt = row["cnt"] or 0
            last_dt = row["last_triggered"]

            # Try exact match first, then prefix/contains
            rule = _EVENT_TO_RULE.get(et)
            if not rule:
                for pattern, r_code in _EVENT_TO_RULE.items():
                    if pattern in et:
                        rule = r_code
                        break
            if not rule:
                rule = "S4"  # default to content compliance

            rule_counts[rule] += cnt
            if last_dt and (rule_last[rule] is None or last_dt > rule_last[rule]):
                rule_last[rule] = last_dt

        return [
            SafetyMetric(
                rule=code, label=label,
                count=rule_counts[code],
                last_triggered=rule_last[code].strftime("%H:%M") if rule_last[code] else None,
            )
            for code, label in _SAFETY_RULES.items()
        ]
    except Exception as e:
        logger.warning("safety/24h fallback: %s", e)
        return [
            SafetyMetric(rule=code, label=label, count=0)
            for code, label in _SAFETY_RULES.items()
        ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8. GET /alerts/active
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/alerts/active", response_model=list[Alert])
async def get_active_alerts(
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """æ´»è·ƒå‘Šè­¦ â€” 5sè½®è¯¢"""
    try:
        alerts: list[Alert] = []

        # System alerts
        r = await db.execute(text("""
            SELECT id, level, message, source, auto_resolved, created_at
            FROM system_alerts WHERE status = 'active'
            ORDER BY CASE level
              WHEN 'critical' THEN 0 WHEN 'warning' THEN 1 ELSE 2
            END, created_at DESC
            LIMIT 20
        """))
        for row in r.mappings():
            lvl = row["level"] or "info"
            if lvl not in ("critical", "warning", "info"):
                lvl = "info"
            alerts.append(Alert(
                id=str(row["id"]),
                level=lvl,
                message=row["message"] or "",
                source=row["source"] or "",
                time=_relative_time(row["created_at"]) if row["created_at"] else "",
                auto_resolved=bool(row["auto_resolved"]),
            ))

        # Device alerts (unresolved, danger severity)
        r = await db.execute(text("""
            SELECT id, severity as level, message, data_type as source, created_at
            FROM device_alerts
            WHERE resolved = false AND severity = 'danger'
            ORDER BY created_at DESC LIMIT 10
        """))
        for row in r.mappings():
            alerts.append(Alert(
                id=f"dev_{row['id']}",
                level="critical",
                message=row["message"] or "",
                source=row["source"] or "",
                time=_relative_time(row["created_at"]) if row["created_at"] else "",
            ))

        return alerts
    except Exception as e:
        logger.warning("alerts/active fallback: %s", e)
        return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 9. POST /alerts/{alert_id}/dismiss
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.post("/alerts/{alert_id}/dismiss", response_model=AlertDismissResponse)
async def dismiss_alert(
    alert_id: str = Path(...),
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """å…³é—­å‘Šè­¦"""
    try:
        if alert_id.startswith("dev_"):
            dev_id = int(alert_id[4:])
            await db.execute(
                text("UPDATE device_alerts SET resolved=true WHERE id=:id"),
                {"id": dev_id},
            )
        else:
            await db.execute(
                text("""
                    UPDATE system_alerts
                    SET status='dismissed', dismissed_by=:uid, dismissed_at=NOW()
                    WHERE id=:id
                """),
                {"id": alert_id, "uid": admin_user.id},
            )
        await db.commit()
        return AlertDismissResponse(success=True, alert_id=alert_id)
    except Exception as e:
        logger.warning("dismiss_alert error: %s", e)
        await db.rollback()
        return AlertDismissResponse(success=False, alert_id=alert_id)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 10. GET /users/overview
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/user-overview", response_model=UserOverview)
async def get_users_overview(
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """ç”¨æˆ·æ€»è§ˆ"""
    try:
        today = date.today()

        # Role breakdown
        r = await db.execute(text("""
            SELECT
              COUNT(*) as total,
              COUNT(*) FILTER (WHERE role::text='OBSERVER') as observers,
              COUNT(*) FILTER (WHERE role::text='GROWER') as growers,
              COUNT(*) FILTER (WHERE role::text='SHARER') as sharers,
              COUNT(*) FILTER (WHERE role::text='COACH') as coaches,
              COUNT(*) FILTER (WHERE role::text='PROMOTER') as promoters,
              COUNT(*) FILTER (WHERE role::text='SUPERVISOR') as supervisors,
              COUNT(*) FILTER (WHERE role::text='MASTER') as masters,
              COUNT(*) FILTER (WHERE role::text='ADMIN') as admins,
              COUNT(*) FILTER (WHERE created_at >= :today) as new_today
            FROM users WHERE is_active = true
        """), {"today": today})
        row = r.mappings().first()

        by_role = {
            "Observer": row["observers"] or 0,
            "Grower": row["growers"] or 0,
            "Sharer": row["sharers"] or 0,
            "Coach": row["coaches"] or 0,
            "Promoter": row["promoters"] or 0,
            "Supervisor": row["supervisors"] or 0,
            "Master": row["masters"] or 0,
            "Admin": row["admins"] or 0,
        } if row else {}

        # Active today: distinct users from chat_messages + daily_tasks
        r = await db.execute(text("""
            SELECT COUNT(DISTINCT uid) FROM (
              SELECT cs.user_id as uid
              FROM chat_messages cm
              JOIN chat_sessions cs ON cs.id = cm.session_id
              WHERE cm.created_at >= :today
              UNION
              SELECT user_id as uid
              FROM daily_tasks WHERE task_date = :today_date
            ) sub
        """), {"today": today, "today_date": today})
        active_today = r.scalar() or 0

        return UserOverview(
            total_users=row["total"] if row else 0,
            by_role=by_role,
            by_stage={},  # Stage data requires assessment pipeline; omit for now
            new_today=row["new_today"] if row else 0,
            active_today=active_today,
        )
    except Exception as e:
        logger.warning("users/overview fallback: %s", e)
        return UserOverview(total_users=0, by_role={}, by_stage={}, new_today=0, active_today=0)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 11. GET /system/containers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/system/containers", response_model=list[ContainerStatus])
async def get_container_status(admin_user=Depends(require_admin)):
    # INFRASTRUCTURE PLACEHOLDER â€” requires Docker API (unix socket or TCP).
    # Returns expected container topology.
    """å®¹å™¨çŠ¶æ€"""
    return [
        ContainerStatus(name="bhp-api", port="8000", status="running", uptime="--", cpu_pct=0, mem_mb=0),
        ContainerStatus(name="bhp-h5", port="5173", status="running", uptime="--", cpu_pct=0, mem_mb=0),
        ContainerStatus(name="bhp-admin-portal", port="5174", status="running", uptime="--", cpu_pct=0, mem_mb=0),
        ContainerStatus(name="bhp-expert-workbench", port="8501", status="running", uptime="--", cpu_pct=0, mem_mb=0),
        ContainerStatus(name="dify-api", port="5001", status="running", uptime="--", cpu_pct=0, mem_mb=0),
        ContainerStatus(name="dify-db", port="5432", status="running", uptime="--", cpu_pct=0, mem_mb=0),
        ContainerStatus(name="dify-redis", port="6379", status="running", uptime="--", cpu_pct=0, mem_mb=0),
    ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 12. GET /audit-log/recent
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@router.get("/audit-log/recent", response_model=list[dict])
async def get_recent_audit_log(
    limit: int = 20,
    admin_user=Depends(require_admin),
    db: AsyncSession = Depends(get_async_db),
):
    """æœ€è¿‘å®¡è®¡æ—¥å¿—"""
    try:
        half = max(limit // 2, 5)

        # Coach review logs
        r1 = await db.execute(text("""
            SELECT l.reviewed_at as time, u.username, l.action, l.review_id as target, '' as detail
            FROM coach_review_logs l
            JOIN users u ON u.id = l.coach_id
            ORDER BY l.reviewed_at DESC LIMIT :half
        """), {"half": half})
        coach_logs = list(r1.mappings())

        # Safety logs
        r2 = await db.execute(text("""
            SELECT created_at as time, 'system' as username, event_type as action,
              event_type as target, COALESCE(LEFT(input_text, 60), '') as detail
            FROM safety_logs ORDER BY created_at DESC LIMIT :half
        """), {"half": half})
        safety_logs = list(r2.mappings())

        # Merge and sort by time desc
        combined = []
        for row in coach_logs:
            dt = row["time"]
            combined.append({
                "time": dt.strftime("%H:%M") if dt else "--:--",
                "user": row["username"] or "unknown",
                "action": row["action"] or "",
                "target": row["target"] or "",
                "detail": row["detail"] or "",
                "_sort": dt or datetime.min,
            })
        for row in safety_logs:
            dt = row["time"]
            combined.append({
                "time": dt.strftime("%H:%M") if dt else "--:--",
                "user": row["username"] or "system",
                "action": row["action"] or "",
                "target": row["target"] or "",
                "detail": row["detail"] or "",
                "_sort": dt or datetime.min,
            })

        combined.sort(key=lambda x: x["_sort"], reverse=True)

        # Remove sort key before returning
        return [{k: v for k, v in item.items() if k != "_sort"} for item in combined[:limit]]
    except Exception as e:
        logger.warning("audit-log/recent fallback: %s", e)
        return []
