"""
RAG æ£€ç´¢å¼•æ“ + å¼•ç”¨æ ‡æ³¨ (v2 â€” æœ¬åœ°ä¼˜å…ˆ)

é€‚é…: åŒæ­¥ SQLAlchemy + numpy ä½™å¼¦ç›¸ä¼¼åº¦ (æ—  pgvector)

æ ¸å¿ƒèŒè´£:
  1. æ ¹æ® agent_id + tenant_id ç¡®å®šæœç´¢èŒƒå›´
  2. ä» DB å–å€™é€‰ chunks â†’ Python å±‚ç®—å‘é‡ç›¸ä¼¼åº¦ + scope_boost â†’ æ’åº
  3. æ„å»ºã€Œæœ¬åœ°ä¼˜å…ˆã€çš„ prompt æ³¨å…¥æ®µ
  4. æ ¼å¼åŒ–å¼•ç”¨æ•°æ®ï¼ŒåŒºåˆ†æ¥æºç±»å‹
"""

import re
import json
import logging
import numpy as np
from datetime import datetime
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Agent â†’ çŸ¥è¯†é¢†åŸŸæ˜ å°„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

AGENT_DOMAIN_MAP: Dict[str, List[str]] = {
    "sleep":         ["sleep", "mental", "behavior"],
    "glucose":       ["glucose", "nutrition", "metabolism"],
    "stress":        ["stress", "mental", "behavior", "tcm"],
    "mental":        ["mental", "psychology", "behavior"],
    "nutrition":     ["nutrition", "metabolism", "tcm"],
    "exercise":      ["exercise", "rehabilitation", "metabolism"],
    "tcm":           ["tcm", "nutrition", "constitution"],
    "crisis":        ["crisis", "mental"],
    "motivation":    ["motivation", "behavior", "psychology"],
    "behavior_rx":   ["behavior", "motivation", "psychology", "habit"],
    "weight":        ["weight", "nutrition", "exercise", "metabolism"],
    "cardiac_rehab": ["cardiac", "exercise", "nutrition", "rehabilitation"],
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Scope ä¼˜å…ˆçº§åŠ æƒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCOPE_BOOST = {
    "tenant":   0.15,    # ä¸“å®¶ç§æœ‰çŸ¥è¯†ï¼šæœ€é«˜ä¼˜å…ˆ
    "domain":   0.08,    # é¢†åŸŸçŸ¥è¯†ï¼šæ¬¡ä¼˜å…ˆ
    "platform": 0.00,    # å¹³å°å…¬å…±ï¼šåŸºå‡†åˆ†
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ¥æºç±»å‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class SourceType:
    """å¼•ç”¨æ¥æºç±»å‹"""
    KNOWLEDGE = "knowledge"        # æœ¬åœ°çŸ¥è¯†åº“
    MODEL_SUPPLEMENT = "model"     # æ¨¡å‹è¡¥å……


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ•°æ®ç»“æ„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class Citation:
    """ä¸€æ¡å¼•ç”¨"""
    index: int                       # [1], [2] ...
    doc_title: str
    heading: str
    author: str
    source: str
    page_number: Optional[int]
    relevance_score: float
    content_preview: str             # å‰150å­—
    chunk_id: int
    document_id: int
    scope: str = "platform"          # tenant/domain/platform
    source_type: str = SourceType.KNOWLEDGE
    evidence_tier: str = ""           # T1/T2/T3/T4

    @property
    def scope_label(self) -> str:
        return {
            "tenant": "ğŸ”’ ä¸“å®¶ç§æœ‰",
            "domain": "ğŸ“‚ é¢†åŸŸçŸ¥è¯†",
            "platform": "ğŸŒ å¹³å°å…¬å…±",
        }.get(self.scope, self.scope)

    @property
    def label(self) -> str:
        parts = [f"[{self.index}]"]
        if self.author:
            parts.append(self.author)
        parts.append(f"ã€Š{self.doc_title}ã€‹")
        if self.heading:
            parts.append(f"> {self.heading}")
        if self.page_number:
            parts.append(f"(ç¬¬{self.page_number}é¡µ)")
        return " ".join(parts)

    @property
    def short_label(self) -> str:
        return f"[{self.index}] {self.doc_title}" + (f" Â· {self.heading}" if self.heading else "")

    def to_dict(self) -> dict:
        d = {
            "index": self.index,
            "label": self.label,
            "shortLabel": self.short_label,
            "docTitle": self.doc_title,
            "heading": self.heading,
            "author": self.author,
            "source": self.source,
            "pageNumber": self.page_number,
            "relevanceScore": round(self.relevance_score, 3),
            "contentPreview": self.content_preview,
            "chunkId": self.chunk_id,
            "documentId": self.document_id,
            "scope": self.scope,
            "scopeLabel": self.scope_label,
            "sourceType": self.source_type,
        }
        if self.evidence_tier:
            d["evidenceTier"] = self.evidence_tier
        return d


@dataclass
class RAGContext:
    """æ£€ç´¢ç»“æœ"""
    query: str
    citations: List[Citation] = field(default_factory=list)
    prompt_injection: str = ""
    domains_searched: List[str] = field(default_factory=list)

    @property
    def has_knowledge(self) -> bool:
        return len(self.citations) > 0

    @property
    def citation_count(self) -> int:
        return len(self.citations)

    def format_response(self, llm_response: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ– LLM å›å¤ + å¼•ç”¨æ•°æ® â†’ å‰ç«¯æ¶ˆè´¹ç»“æ„"""
        used = sorted(set(int(r) for r in re.findall(r'\[(\d+)\]', llm_response)))
        model_sections = self._extract_model_supplements(llm_response)
        has_supplement = len(model_sections) > 0

        scope_breakdown = {}
        for c in self.citations:
            if c.index in used:
                scope_breakdown[c.scope] = scope_breakdown.get(c.scope, 0) + 1

        return {
            "text": llm_response,
            "hasKnowledge": self.has_knowledge,
            "citationsUsed": used,
            "citations": [c.to_dict() for c in self.citations if c.index in used],
            "knowledgeCitations": [
                c.to_dict() for c in self.citations
                if c.index in used and c.source_type == SourceType.KNOWLEDGE
            ],
            "hasModelSupplement": has_supplement,
            "modelSupplementSections": model_sections,
            "allCitations": [c.to_dict() for c in self.citations],
            "domainsSearched": self.domains_searched,
            "sourceStats": {
                "knowledgeCount": len([c for c in self.citations if c.index in used]),
                "modelSupplement": has_supplement,
                "scopeBreakdown": scope_breakdown,
            },
        }

    @staticmethod
    def _extract_model_supplements(text: str) -> List[str]:
        """æå– LLM å›å¤ä¸­çš„æ¨¡å‹è¡¥å……æ®µè½"""
        sections = []
        pattern1 = re.findall(r'ã€(?:è¡¥å……|æ¨¡å‹è¡¥å……|è¡¥å……è¯´æ˜)ã€‘\s*(.+?)(?=\n\n|\nã€|$)', text, re.DOTALL)
        sections.extend(pattern1)
        pattern2 = re.findall(r'\*{0,2}è¡¥å……è¯´æ˜\*{0,2}[:ï¼š]\s*(.+?)(?=\n\n|\nã€|$)', text, re.DOTALL)
        sections.extend(pattern2)
        pattern3 = re.findall(r'ã€ä»¥ä¸‹ä¸ºé€šç”¨ä¸“ä¸šçŸ¥è¯†[^ã€‘]*ã€‘\s*(.+?)(?=$)', text, re.DOTALL)
        sections.extend(pattern3)
        return [s.strip() for s in sections if s.strip()]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä½™å¼¦ç›¸ä¼¼åº¦ (numpy)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _cosine_similarity(a: List[float], b: List[float]) -> float:
    """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
    a_arr = np.array(a, dtype=np.float32)
    b_arr = np.array(b, dtype=np.float32)
    norm_a = np.linalg.norm(a_arr)
    norm_b = np.linalg.norm(b_arr)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return float(np.dot(a_arr, b_arr) / (norm_a * norm_b))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ£€ç´¢å¼•æ“
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class KnowledgeRetriever:
    """
    çŸ¥è¯†æ£€ç´¢å¼•æ“ (v2 â€” æœ¬åœ°ä¼˜å…ˆ)

    é€‚é…: åŒæ­¥ Session + numpy ä½™å¼¦ç›¸ä¼¼åº¦
    """

    def __init__(self, db: Session, embedder):
        self.db = db
        self.embedder = embedder

    def retrieve(
        self,
        query: str,
        agent_id: str = "",
        tenant_id: str = "",
        top_k: int = 5,
        min_score: float = 0.35,
    ) -> RAGContext:
        """
        ä¸»å…¥å£: æ ¹æ® Agent + ç§Ÿæˆ·ä¸Šä¸‹æ–‡åšè¯­ä¹‰æ£€ç´¢

        ç­–ç•¥:
          1. SQL æŸ¥å€™é€‰ chunks (scope æ¡ä»¶è¿‡æ»¤)
          2. Python å±‚ numpy ä½™å¼¦ç›¸ä¼¼åº¦
          3. + scope_boost + doc_priority åŠ æƒ
          4. æ’åºå– top_k
        """
        from core.models import KnowledgeChunk, KnowledgeDocument

        domains = AGENT_DOMAIN_MAP.get(agent_id, ["general"])

        # 1. å‘é‡åŒ–æŸ¥è¯¢
        query_vector = self.embedder.embed_query(query)
        if not query_vector:
            logger.warning("æŸ¥è¯¢å‘é‡ä¸ºç©º, è·³è¿‡ RAG")
            return RAGContext(query=query, domains_searched=domains)

        # 2. SQL æŸ¥å€™é€‰ chunks
        q = self.db.query(KnowledgeChunk).join(
            KnowledgeDocument,
            KnowledgeChunk.document_id == KnowledgeDocument.id,
        ).filter(
            KnowledgeDocument.is_active == True,
            KnowledgeDocument.status == "ready",
            KnowledgeChunk.embedding_1024.isnot(None),
        )

        # scope æ¡ä»¶
        from sqlalchemy import or_
        scope_conds = []
        if tenant_id:
            scope_conds.append(
                (KnowledgeChunk.scope == "tenant") & (KnowledgeChunk.tenant_id == tenant_id)
            )
        scope_conds.append(
            (KnowledgeChunk.scope == "domain") & (KnowledgeChunk.domain_id.in_(domains))
        )
        scope_conds.append(
            (KnowledgeChunk.scope == "platform") &
            (KnowledgeChunk.domain_id.in_(domains + ["general"]))
        )
        q = q.filter(or_(*scope_conds))

        candidates = q.all()

        if not candidates:
            logger.info(f"RAG: æ— å€™é€‰ chunks (agent={agent_id}, domains={domains})")
            return RAGContext(
                query=query,
                prompt_injection=KnowledgeRetriever._build_no_knowledge_injection(),
                domains_searched=domains,
            )

        # 3. Python å±‚è®¡ç®—ç›¸ä¼¼åº¦ + scope_boost
        scored = []
        for chunk in candidates:
            try:
                chunk_vec = json.loads(chunk.embedding_1024)
            except (json.JSONDecodeError, TypeError):
                continue

            raw_score = _cosine_similarity(query_vector, chunk_vec)
            if raw_score < min_score:
                continue

            boost = SCOPE_BOOST.get(chunk.scope, 0.0)

            # doc_priority å¾®è°ƒ: (priority - 5) * 0.01
            doc = self.db.query(KnowledgeDocument).filter(
                KnowledgeDocument.id == chunk.document_id
            ).first()
            priority_adj = ((doc.priority or 5) - 5) * 0.01 if doc else 0.0

            # freshness_penalty: è¿‡æœŸæ–‡æ¡£è½»å¾®é™æƒ
            freshness_penalty = 0.0
            now = datetime.utcnow()
            if doc and doc.expires_at and doc.expires_at < now:
                days_expired = (now - doc.expires_at).days
                freshness_penalty = min(days_expired * 0.005, 0.10)

            boosted = raw_score + boost + priority_adj - freshness_penalty
            scored.append((chunk, raw_score, boosted, doc))

        # 4. æ’åºå– top_k
        scored.sort(key=lambda x: x[2], reverse=True)
        top_results = scored[:top_k]

        # 5. æ„å»ºå¼•ç”¨åˆ—è¡¨
        citations = []
        for i, (chunk, raw, boosted, doc) in enumerate(top_results):
            preview = chunk.content[:150] + "..." if len(chunk.content) > 150 else chunk.content
            citations.append(Citation(
                index=i + 1,
                doc_title=chunk.doc_title or "æœªçŸ¥æ–‡æ¡£",
                heading=chunk.heading or "",
                author=chunk.doc_author or "",
                source=chunk.doc_source or "",
                page_number=chunk.page_number,
                relevance_score=boosted,
                content_preview=preview,
                chunk_id=chunk.id,
                document_id=chunk.document_id,
                scope=chunk.scope or "platform",
                source_type=SourceType.KNOWLEDGE,
                evidence_tier=getattr(doc, 'evidence_tier', '') or "",
            ))

        # 6. æ„å»º prompt æ³¨å…¥
        prompt_injection = self._build_injection(citations, top_results)

        if citations:
            scope_summary = {}
            for c in citations:
                scope_summary[c.scope] = scope_summary.get(c.scope, 0) + 1
            logger.info(
                f"ğŸ“š RAG: {agent_id}@{tenant_id} | "
                f"{len(citations)} æ¡ | scope: {scope_summary}"
            )

        return RAGContext(
            query=query,
            citations=citations,
            prompt_injection=prompt_injection,
            domains_searched=domains,
        )

    def _build_injection(self, citations: List[Citation], top_results) -> str:
        """æ„å»ºã€Œæœ¬åœ°ä¼˜å…ˆã€çš„ prompt æ³¨å…¥æ®µ"""
        if not citations:
            return self._build_no_knowledge_injection()

        # æŒ‰ scope åˆ†ç»„
        tenant_refs, domain_refs, platform_refs = [], [], []
        for cite, (chunk, raw, boosted, doc) in zip(citations, top_results):
            block = self._format_ref_block(cite, chunk)
            if cite.scope == "tenant":
                tenant_refs.append(block)
            elif cite.scope == "domain":
                domain_refs.append(block)
            else:
                platform_refs.append(block)

        knowledge_blocks = []

        if tenant_refs:
            knowledge_blocks.append(
                f"â”â”â” ğŸ”’ ä¸“å®¶ç§æœ‰èµ„æ–™ (æœ€é«˜ä¼˜å…ˆ) â”â”â”\n"
                f"{''.join(tenant_refs)}"
            )
        if domain_refs:
            knowledge_blocks.append(
                f"â”â”â” ğŸ“‚ é¢†åŸŸä¸“ä¸šçŸ¥è¯† â”â”â”\n"
                f"{''.join(domain_refs)}"
            )
        if platform_refs:
            knowledge_blocks.append(
                f"â”â”â” ğŸŒ å¹³å°é€šç”¨çŸ¥è¯† â”â”â”\n"
                f"{''.join(platform_refs)}"
            )

        return f"""
<knowledge_base>
ä»¥ä¸‹æ˜¯ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³çš„ä¸“ä¸šçŸ¥è¯†èµ„æ–™ï¼Œæ¥è‡ªæœ¬å¹³å°çŸ¥è¯†åº“ã€‚

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å›ç­”è§„åˆ™ (ä¸¥æ ¼éµå®ˆ):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. **æœ¬åœ°çŸ¥è¯†ä¼˜å…ˆ**: å›ç­”æ—¶å¿…é¡»ä¼˜å…ˆä½¿ç”¨ä¸‹æ–¹çš„çŸ¥è¯†åº“å‚è€ƒèµ„æ–™
   ä¼˜å…ˆçº§: ä¸“å®¶ç§æœ‰èµ„æ–™ > é¢†åŸŸä¸“ä¸šçŸ¥è¯† > å¹³å°é€šç”¨çŸ¥è¯†
   åªè¦å‚è€ƒèµ„æ–™ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå°±å¿…é¡»å¼•ç”¨ï¼Œä¸å¾—è·³è¿‡

2. **å¼•ç”¨æ ‡æ³¨**: å¼•ç”¨çŸ¥è¯†åº“å†…å®¹æ—¶ç”¨ [1] [2] ç­‰ç¼–å·æ ‡è®°å‡ºå¤„
   åŒä¸€æ®µè¯å¦‚æ¶‰åŠå¤šæ¡èµ„æ–™ï¼Œåº”æ ‡æ³¨æ‰€æœ‰ç›¸å…³ç¼–å·

3. **æœ¬åœ°èµ„æ–™ä¸æ¨¡å‹çŸ¥è¯†æœ‰å†²çªæ—¶**: ä»¥æœ¬åœ°èµ„æ–™ä¸ºå‡†
   æœ¬åœ°èµ„æ–™æ˜¯ä¸“å®¶å®¡æ ¸è¿‡çš„æƒå¨å†…å®¹ï¼Œä¸å¯è¢«æ¨¡å‹çŸ¥è¯†è¦†ç›–

4. **æ¨¡å‹çŸ¥è¯†è¡¥å……** (ä»…åœ¨ä»¥ä¸‹æƒ…å†µä½¿ç”¨):
   - çŸ¥è¯†åº“èµ„æ–™ä¸è¶³ä»¥å®Œæ•´å›ç­”ç”¨æˆ·é—®é¢˜
   - ç”¨æˆ·è¿½é—®äº†çŸ¥è¯†åº“æœªæ¶µç›–çš„å†…å®¹
   ä½¿ç”¨æ¨¡å‹çŸ¥è¯†æ—¶ï¼Œå¿…é¡»ç”¨ã€Œã€è¡¥å……ã€‘ã€æ ‡è®°å¼€å¤´ï¼Œä¾‹å¦‚:
   ã€è¡¥å……ã€‘æ ¹æ®ä¸€èˆ¬ä¸´åºŠç»éªŒï¼Œ...
   æ²¡æœ‰è¿™ä¸ªæ ‡è®°çš„å†…å®¹ï¼Œç”¨æˆ·ä¼šè®¤ä¸ºæ¥è‡ªçŸ¥è¯†åº“

5. **ç¦æ­¢ç¼–é€ **: ä¸å¾—ç¼–é€ çŸ¥è¯†åº“ä¸­æ²¡æœ‰çš„å…·ä½“æ•°æ®ã€æ¯”ä¾‹ã€æ–¹æ¡ˆ
   å¦‚ä¸ç¡®å®šï¼Œå®å¯è¯´"å»ºè®®è¿›ä¸€æ­¥å’¨è¯¢"ä¹Ÿä¸ç¼–

6. **å›ç­”ç»“æ„** (æ¨è):
   - å…ˆç”¨çŸ¥è¯†åº“èµ„æ–™ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ [å¸¦å¼•ç”¨ç¼–å·]
   - å¦‚æœ‰ä¸è¶³ï¼Œå†ç”¨ã€Œã€è¡¥å……ã€‘ã€æ®µè¡¥å……
   - æœ€åå¯ç»™å‡ºå»ºè®®

{"".join(knowledge_blocks)}
</knowledge_base>
"""

    @staticmethod
    def _build_no_knowledge_injection() -> str:
        """æ— çŸ¥è¯†åº“å‘½ä¸­æ—¶çš„ prompt"""
        return """
<knowledge_note>
å½“å‰é—®é¢˜æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›´æ¥ç›¸å…³çš„èµ„æ–™ã€‚
è¯·ä½¿ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†å›ç­”ï¼Œä½†éœ€æ³¨æ„:
1. åœ¨å›å¤å¼€å¤´æ ‡æ˜: ã€ä»¥ä¸‹ä¸ºé€šç”¨ä¸“ä¸šçŸ¥è¯†ï¼Œéæœ¬å¹³å°ä¸“å±èµ„æ–™ã€‘
2. ä¸è¦ç¼–é€ å…·ä½“çš„æ•°æ®ã€æ¯”ä¾‹æˆ–ç ”ç©¶å¼•ç”¨
3. å¦‚æ¶‰åŠå…·ä½“æ²»ç–—æ–¹æ¡ˆï¼Œå»ºè®®ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
</knowledge_note>
"""

    @staticmethod
    def _format_ref_block(cite: 'Citation', chunk) -> str:
        """æ ¼å¼åŒ–å•æ¡å‚è€ƒèµ„æ–™"""
        source_info = f"æ¥æº: {cite.author + 'ï¼Œ' if cite.author else ''}ã€Š{cite.doc_title}ã€‹"
        if cite.heading:
            source_info += f" > {cite.heading}"
        if cite.page_number:
            source_info += f" (ç¬¬{cite.page_number}é¡µ)"

        return f"""
--- å‚è€ƒèµ„æ–™ [{cite.index}] ---
{source_info}
ç›¸å…³åº¦: {cite.relevance_score:.0%}

{chunk.content}
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Agent é›†æˆè¾…åŠ©å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_rag_prompt(
    base_system_prompt: str,
    rag_context: RAGContext,
    persona: dict = None,
) -> str:
    """æ„å»º RAG å¢å¼ºåçš„ç³»ç»Ÿ prompt"""
    parts = [base_system_prompt]

    if persona:
        if persona.get("name"):
            parts.append(f"\nä½ çš„èº«ä»½: {persona['name']}")
        if persona.get("tone"):
            parts.append(f"ä½ çš„è¯­æ°”é£æ ¼: {persona['tone']}")

    parts.append(rag_context.prompt_injection)
    return "\n".join(parts)
