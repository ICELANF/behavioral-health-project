"""
Agent å¯¹è¯ RAG ä¸­é—´ä»¶ (åŒæ­¥ç‰ˆ)

èƒ¶æ°´å±‚: åœ¨è°ƒç”¨ LLM ä¹‹å‰æ£€ç´¢çŸ¥è¯† â†’ æ³¨å…¥ prompt â†’ åŒ…è£…å›å¤ + å¼•ç”¨æ•°æ®ã€‚

ç”¨æ³•:
    from core.knowledge import rag_enhance, record_citations

    enhanced = rag_enhance(db, "ç³–å°¿ç—…èƒ½åƒæ°´æœå—", agent_id="nutrition")
    response = llm.chat(system=enhanced.system_prompt, ...)
    result = enhanced.wrap_response(response.text)
"""

import re
import logging
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å¢å¼ºç»“æœ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class RAGEnhancedContext:
    """RAG å¢å¼ºåçš„ä¸Šä¸‹æ–‡"""
    system_prompt: str
    has_knowledge: bool = False
    citation_count: int = 0
    domains_searched: List[str] = field(default_factory=list)
    _rag_context: Any = None

    def wrap_response(self, llm_response: str) -> Dict[str, Any]:
        """åŒ…è£… LLM å›å¤ + å¼•ç”¨æ•°æ®"""
        if self._rag_context:
            return self._rag_context.format_response(llm_response)

        model_sections = re.findall(
            r'ã€(?:è¡¥å……|æ¨¡å‹è¡¥å……|è¡¥å……è¯´æ˜|ä»¥ä¸‹ä¸ºé€šç”¨ä¸“ä¸šçŸ¥è¯†[^ã€‘]*)ã€‘\s*(.+?)(?=\n\n|$)',
            llm_response, re.DOTALL
        )

        return {
            "text": llm_response,
            "hasKnowledge": False,
            "citationsUsed": [],
            "citations": [],
            "knowledgeCitations": [],
            "hasModelSupplement": len(model_sections) > 0 or not self._rag_context,
            "modelSupplementSections": [s.strip() for s in model_sections if s.strip()],
            "allCitations": [],
            "domainsSearched": self.domains_searched,
            "sourceStats": {
                "knowledgeCount": 0,
                "modelSupplement": True,
                "scopeBreakdown": {},
            },
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…¨å±€ Embedder å•ä¾‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_embedder_instance = None

def _get_embedder():
    """æ‡’åŠ è½½ Embedding æœåŠ¡ (å…¨å±€å•ä¾‹)"""
    global _embedder_instance
    if _embedder_instance is None:
        from .embedding_service import EmbeddingService
        _embedder_instance = EmbeddingService()
        logger.info("âœ… RAG Embedding æœåŠ¡å·²åŠ è½½ (Ollama mxbai-embed-large, 1024ç»´)")
    return _embedder_instance


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ ¸å¿ƒå‡½æ•°: rag_enhance
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def rag_enhance(
    db: Session,
    query: str,
    agent_id: str = "",
    tenant_id: str = "",
    base_system_prompt: str = "",
    persona: dict = None,
    top_k: int = 5,
    min_score: float = 0.35,
) -> RAGEnhancedContext:
    """
    ä¸€ç«™å¼ RAG å¢å¼º (åŒæ­¥ç‰ˆ)

    è¾“å…¥: ç”¨æˆ·é—®é¢˜ + Agent/ç§Ÿæˆ·ä¸Šä¸‹æ–‡ + åŸå§‹ç³»ç»Ÿæç¤º
    è¾“å‡º: å¢å¼ºåçš„ç³»ç»Ÿæç¤º + å¼•ç”¨åŒ…è£…å™¨
    """
    from .retriever import KnowledgeRetriever, build_rag_prompt

    embedder = _get_embedder()
    retriever = KnowledgeRetriever(db, embedder)

    rag_context = retriever.retrieve(
        query=query,
        agent_id=agent_id,
        tenant_id=tenant_id,
        top_k=top_k,
        min_score=min_score,
    )

    system_prompt = build_rag_prompt(base_system_prompt, rag_context, persona)

    if rag_context.has_knowledge:
        logger.info(
            f"ğŸ“š RAG: {agent_id}@{tenant_id} â†’ "
            f"æ‰¾åˆ° {len(rag_context.citations)} æ¡, "
            f"é¢†åŸŸ {rag_context.domains_searched}"
        )

    return RAGEnhancedContext(
        system_prompt=system_prompt,
        has_knowledge=rag_context.has_knowledge,
        citation_count=len(rag_context.citations),
        domains_searched=rag_context.domains_searched,
        _rag_context=rag_context,
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å¼•ç”¨è®°å½• (å®¡è®¡è¿½è¸ª)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def record_citations(
    db: Session,
    enhanced: RAGEnhancedContext,
    llm_response: str,
    session_id: str = "",
    message_id: str = "",
    agent_id: str = "",
    tenant_id: str = "",
    user_id: str = "",
):
    """è®°å½•å¼•ç”¨åˆ° knowledge_citations è¡¨"""
    if not enhanced._rag_context or not enhanced._rag_context.has_knowledge:
        return

    from core.models import KnowledgeCitation

    used_indexes = set(int(r) for r in re.findall(r'\[(\d+)\]', llm_response))

    for cite in enhanced._rag_context.citations:
        if cite.index not in used_indexes:
            continue

        record = KnowledgeCitation(
            session_id=session_id,
            message_id=message_id,
            agent_id=agent_id,
            tenant_id=tenant_id,
            user_id=user_id,
            chunk_id=cite.chunk_id,
            document_id=cite.document_id,
            query_text=enhanced._rag_context.query[:500],
            relevance_score=cite.relevance_score,
            rank_position=cite.index,
            citation_text=cite.content_preview[:500],
            citation_label=cite.label,
        )
        db.add(record)

    try:
        db.commit()
        logger.info(f"ğŸ“ å¼•ç”¨è®°å½•: {len(used_indexes)} æ¡å†™å…¥ citations è¡¨")
    except Exception as e:
        db.rollback()
        logger.error(f"å¼•ç”¨è®°å½•å†™å…¥å¤±è´¥: {e}")
