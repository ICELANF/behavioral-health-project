#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
data_extractor.py - å¥åº·æ•°æ®æå–æ¨¡å—

ä¼˜å…ˆçº§ç­–ç•¥ï¼š
1. ä¼˜å…ˆä» Excel (.xlsx) è¯»å–ç”Ÿç†æŒ‡æ ‡ï¼ˆSDNN, RMSSD, HRV ç­‰ï¼‰
2. PDF ä»…ç”¨äºæå–ç„¦è™‘åˆ†æ•°å’Œ SCL-90 å› å­åˆ†
3. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡ç³ŠåŒ¹é…æå–æ•°å€¼
4. å¼‚å¸¸å›é€€æœºåˆ¶ï¼šè§£æå¤±è´¥æ—¶ç»™å‡ºæ˜ç¡®æç¤º
"""

import re
import sys
import io
import os
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, field
from datetime import datetime

import pandas as pd

# Windows æ§åˆ¶å°ç¼–ç ä¿®å¤ï¼ˆä»…åœ¨ç›´æ¥è¿è¡Œæ—¶æ‰§è¡Œï¼Œé¿å…é‡å¤åŒ…è£…ï¼‰
def _fix_windows_encoding():
    """ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜"""
    if sys.platform == 'win32':
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ TextIOWrapper
            if not isinstance(sys.stdout, io.TextIOWrapper) or sys.stdout.encoding != 'utf-8':
                if hasattr(sys.stdout, 'buffer'):
                    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
            if not isinstance(sys.stderr, io.TextIOWrapper) or sys.stderr.encoding != 'utf-8':
                if hasattr(sys.stderr, 'buffer'):
                    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
        except Exception:
            pass  # å¿½ç•¥ç¼–ç ä¿®å¤å¤±è´¥


@dataclass
class ExtractionResult:
    """æ•°æ®æå–ç»“æœ"""
    # ç”Ÿç†æ•°æ®ï¼ˆæ¥è‡ª Excelï¼‰
    physio_data: Dict[str, Any] = field(default_factory=dict)
    physio_source: str = ""  # æ•°æ®æ¥æºæ–‡ä»¶
    physio_success: bool = False

    # å¿ƒç†æ•°æ®ï¼ˆæ¥è‡ª PDF æˆ– Excelï¼‰
    psych_data: Dict[str, Any] = field(default_factory=dict)
    psych_source: str = ""
    psych_success: bool = False

    # è§£æå¤±è´¥çš„å­—æ®µ
    failed_fields: List[str] = field(default_factory=list)

    # è­¦å‘Šä¿¡æ¯
    warnings: List[str] = field(default_factory=list)

    # åŸå§‹æ•°æ®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    raw_excel_physio: Optional[pd.DataFrame] = None
    raw_excel_psych: Optional[pd.DataFrame] = None
    raw_pdf_text: str = ""


# ============ æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ ============
# å¢å¼ºæ¨¡ç³ŠåŒ¹é…ï¼šä½¿ç”¨ [\s:ï¼š=\-_\(\)ï¼ˆï¼‰\[\]ã€ã€‘]* å®¹å¿ä»»æ„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
# SEP ç”¨äºåŒ¹é…å…³é”®è¯å’Œæ•°å€¼ä¹‹é—´çš„ä»»æ„åˆ†éš”ç¬¦
SEP = r'[\s:ï¼š=\-_\(\)ï¼ˆï¼‰\[\]ã€ã€‘\|ï½œ/ï¼\.,ï¼Œã€‚]*'

REGEX_PATTERNS = {
    # HRV ç”Ÿç†æŒ‡æ ‡ï¼ˆé€šå¸¸åœ¨ Excel ä¸­ï¼‰
    "SDNN": rf"SDNN{SEP}(\d+\.?\d*)",
    "RMSSD": rf"RMSSD{SEP}(\d+\.?\d*)",
    "pNN50": rf"[pP]NN50{SEP}(\d+\.?\d*)",
    "LF": rf"(?<![A-Za-z])LF{SEP}(\d+\.?\d*)",
    "HF": rf"(?<![A-Za-z])HF{SEP}(\d+\.?\d*)",
    "LF_HF_ratio": rf"LF[/ï¼\s]*HF{SEP}(\d+\.?\d*)",
    "TP": rf"(?:TP|æ€»åŠŸç‡|Total\s*Power){SEP}(\d+\.?\d*)",

    # å¿ƒç‡æŒ‡æ ‡
    "heart_rate": rf"(?:å¹³å‡å¿ƒç‡|å¿ƒç‡|HR|Heart\s*Rate){SEP}(\d+\.?\d*)",
    "heart_rate_max": rf"(?:æœ€å¤§å¿ƒç‡|æœ€é«˜å¿ƒç‡|Max\s*HR|å³°å€¼å¿ƒç‡){SEP}(\d+\.?\d*)",
    "heart_rate_min": rf"(?:æœ€å°å¿ƒç‡|æœ€ä½å¿ƒç‡|Min\s*HR|è°·å€¼å¿ƒç‡){SEP}(\d+\.?\d*)",

    # å¿ƒç†æŒ‡æ ‡ï¼ˆéœ€è¦ä» PDF æå–ï¼‰
    "anxiety_score": rf"(?:ç„¦è™‘[åˆ†å¾—è¯„æŒ‡]?[æ•°åˆ†å€¼]?|SAS[åˆ†å¾—]?[æ•°åˆ†]?|ç„¦è™‘é‡è¡¨|ç„¦è™‘è‡ªè¯„|Anxiety){SEP}(\d+\.?\d*)",
    "depression_score": rf"(?:æŠ‘éƒ[åˆ†å¾—è¯„æŒ‡]?[æ•°åˆ†å€¼]?|SDS[åˆ†å¾—]?[æ•°åˆ†]?|æŠ‘éƒé‡è¡¨|æŠ‘éƒè‡ªè¯„|Depression){SEP}(\d+\.?\d*)",
    "stress_index": rf"(?:å‹åŠ›[æŒ‡åˆ†]?[æ•°åˆ†å€¼]?|å¿ƒç†å‹åŠ›|Stress){SEP}(\d+\.?\d*)",
    "fatigue_index": rf"(?:ç–²åŠ³[æŒ‡åˆ†]?[æ•°åˆ†å€¼]?|ç–²åŠ³åº¦|Fatigue){SEP}(\d+\.?\d*)",

    # SCL-90 å› å­åˆ† - å¢å¼ºæ¨¡ç³ŠåŒ¹é…
    "scl90_total": rf"(?:SCL[-_\s]?90|ç—‡çŠ¶è‡ªè¯„){SEP}(?:æ€»åˆ†|æ€»å‡åˆ†|æ€»|Total)?{SEP}(\d+\.?\d*)",
    "scl90_somatization": rf"(?:èº¯ä½“åŒ–|èº¯ä½“ä¸é€‚|Somatization){SEP}(\d+\.?\d*)",
    "scl90_obsessive": rf"(?:å¼ºè¿«[ç—‡çŠ¶]?|å¼ºè¿«è§‚å¿µ|Obsessive){SEP}(\d+\.?\d*)",
    "scl90_interpersonal": rf"(?:äººé™…[å…³ç³»æ•æ„Ÿ]?|äººé™…å…³ç³»|Interpersonal){SEP}(\d+\.?\d*)",
    "scl90_depression": rf"(?:æŠ‘éƒ[ç—‡çŠ¶å› å­]?|SCL.*æŠ‘éƒ){SEP}(\d+\.?\d*)",
    "scl90_anxiety": rf"(?:ç„¦è™‘[ç—‡çŠ¶å› å­]?|SCL.*ç„¦è™‘){SEP}(\d+\.?\d*)",
    "scl90_hostility": rf"(?:æ•Œå¯¹[æ€§æƒ…]?|æ•Œæ„|Hostility){SEP}(\d+\.?\d*)",
    "scl90_phobic": rf"(?:ææ€–|ææƒ§|Phobic){SEP}(\d+\.?\d*)",
    "scl90_paranoid": rf"(?:åæ‰§|å¦„æƒ³|Paranoid){SEP}(\d+\.?\d*)",
    "scl90_psychoticism": rf"(?:ç²¾ç¥ç—…æ€§|ç²¾ç¥è´¨|Psychoticism){SEP}(\d+\.?\d*)",
    "scl90_other": rf"(?:å…¶ä»–|é™„åŠ [é¡¹å› å­]?|ç¡çœ é¥®é£Ÿ){SEP}(\d+\.?\d*)",
}

# Excel åˆ—åæ˜ å°„ï¼ˆä¸­æ–‡ -> æ ‡å‡†åï¼‰
EXCEL_COLUMN_MAP = {
    # ç”Ÿç†æŒ‡æ ‡
    "SDNN": "SDNN",
    "RMSSD": "RMSSD",
    "PNN50": "pNN50",
    "pNN50": "pNN50",
    "LF": "LF",
    "HF": "HF",
    "å¹³å‡å¿ƒç‡": "heart_rate",
    "æœ€å¤§å¿ƒç‡": "heart_rate_max",
    "æœ€å°å¿ƒç‡": "heart_rate_min",
    "æœ€é«˜å¿ƒç‡": "heart_rate_max",
    "æœ€ä½å¿ƒç‡": "heart_rate_min",
    "å¿ƒç‡æ ‡å‡†å·®": "heart_rate_std",
    "å˜å¼‚ç³»æ•°": "cv",
    "RRIå‡å€¼": "rri_mean",
    "å‘¼å¸": "respiration",
    "äº¤æ„ŸçŠ¶æ€": "sympathetic_state",
    "ä½é¢‘å½’ä¸€åŒ–å•ä½": "lf_norm",
    "é«˜é¢‘å½’ä¸€åŒ–å•ä½": "hf_norm",

    # å¿ƒç†æŒ‡æ ‡
    "å‹åŠ›": "stress_index",
    "ç–²åŠ³": "fatigue_index",
    "ç²¾åŠ›": "energy",
    "æƒ…ç»ª": "mood",
    "æƒ…ç»ªçŠ¶æ€": "mood_state",
}


def find_matching_files(data_dir: str, user_id: str = None) -> Dict[str, List[Path]]:
    """
    åœ¨æ•°æ®ç›®å½•ä¸­æŸ¥æ‰¾åŒ¹é…çš„ Excel å’Œ PDF æ–‡ä»¶

    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        user_id: å¯é€‰çš„ç”¨æˆ· IDï¼ˆå¦‚ C302A07E7F52ï¼‰

    Returns:
        åŒ…å« 'physio_excel', 'psych_excel', 'pdf' çš„æ–‡ä»¶è·¯å¾„å­—å…¸
    """
    data_path = Path(data_dir)
    result = {
        "physio_excel": [],
        "psych_excel": [],
        "pdf": []
    }

    if not data_path.exists():
        return result

    for file in data_path.iterdir():
        if not file.is_file():
            continue

        name = file.name

        # å¦‚æœæŒ‡å®šäº† user_idï¼ŒåªåŒ¹é…å¯¹åº”ç”¨æˆ·çš„æ–‡ä»¶
        if user_id and user_id not in name:
            continue

        if name.endswith('.xlsx'):
            if 'ç”Ÿç†æµ‹è¯„' in name:
                result["physio_excel"].append(file)
            elif 'å¿ƒç†æµ‹è¯„' in name:
                result["psych_excel"].append(file)
        elif name.endswith('.pdf'):
            if 'å¿ƒç†å¥åº·' in name or 'æµ‹è¯„æŠ¥å‘Š' in name:
                result["pdf"].append(file)

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
    for key in result:
        result[key].sort(key=lambda x: x.stat().st_mtime, reverse=True)

    return result


def _clean_column_name(col_name: str) -> str:
    """
    æ¸…æ´—åˆ—åï¼šå»æ‰ç©ºæ ¼ã€æ¢è¡Œç¬¦ã€ç‰¹æ®Šå­—ç¬¦

    Args:
        col_name: åŸå§‹åˆ—å

    Returns:
        æ¸…æ´—åçš„åˆ—å
    """
    if not isinstance(col_name, str):
        col_name = str(col_name)
    # å»æ‰ç©ºæ ¼ã€æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦
    cleaned = re.sub(r'[\s\n\r\t]+', '', col_name)
    # å»æ‰ç‰¹æ®Šå­—ç¬¦ä½†ä¿ç•™ä¸­æ–‡å’Œå­—æ¯æ•°å­—
    cleaned = re.sub(r'[^\w\u4e00-\u9fff]', '', cleaned)
    return cleaned


def _get_sheet_count(excel_path: str) -> int:
    """
    ä½¿ç”¨ openpyxl è·å– Sheet æ•°é‡

    Args:
        excel_path: Excel æ–‡ä»¶è·¯å¾„

    Returns:
        Sheet æ•°é‡
    """
    try:
        from openpyxl import load_workbook
        wb = load_workbook(excel_path, read_only=True, data_only=True)
        count = len(wb.sheetnames)
        wb.close()
        return count
    except Exception:
        return 1


def _find_best_sheet_index(excel_path: str) -> Tuple[int, List[str]]:
    """
    ä½¿ç”¨ openpyxl æŸ¥æ‰¾æœ€ä½³ Sheet ç´¢å¼•

    ä¼˜å…ˆçº§åŒ¹é…å…³é”®è¯ï¼Œè¿”å›ç´¢å¼•è€Œéåç§°

    Args:
        excel_path: Excel æ–‡ä»¶è·¯å¾„

    Returns:
        (æœ€ä½³ Sheet ç´¢å¼•, æ‰€æœ‰ Sheet ååˆ—è¡¨)
    """
    try:
        from openpyxl import load_workbook
        wb = load_workbook(excel_path, read_only=True, data_only=True)
        sheet_names = wb.sheetnames
        wb.close()

        if not sheet_names:
            return 0, []

        # ä¼˜å…ˆçº§åŒ¹é…å…³é”®è¯
        priority_keywords = [
            ['ç”Ÿç†', 'æµ‹è¯„'],
            ['ç”Ÿç†'],
            ['HRV'],
            ['physio'],
            ['å¿ƒç‡', 'å˜å¼‚'],
            ['æ•°æ®'],
        ]

        for keywords in priority_keywords:
            for idx, sheet in enumerate(sheet_names):
                sheet_lower = sheet.lower()
                if all(kw.lower() in sheet_lower for kw in keywords):
                    return idx, sheet_names

        # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ª Sheetï¼ˆç´¢å¼• 0ï¼‰
        return 0, sheet_names

    except Exception as e:
        print(f"[è­¦å‘Š] è¯»å– Sheet åˆ—è¡¨å¤±è´¥: {e}")
        return 0, []


def extract_from_excel_physio(excel_path: str) -> Tuple[Dict[str, Any], pd.DataFrame]:
    """
    ä»ç”Ÿç†æµ‹è¯„ Excel æ–‡ä»¶ä¸­æå–æ•°æ®

    æ”¹è¿›ï¼š
    1. ä½¿ç”¨ openpyxl ä½œä¸ºå¼•æ“
    2. é€šè¿‡ Sheet ç´¢å¼•åŠ è½½æ•°æ®ï¼ˆé¿å…ç¼–ç é—®é¢˜ï¼‰
    3. æ¸…æ´—åˆ—åï¼ˆå»æ‰ç©ºæ ¼å’Œæ¢è¡Œç¬¦ï¼‰

    Args:
        excel_path: Excel æ–‡ä»¶è·¯å¾„

    Returns:
        (æå–çš„æ•°æ®å­—å…¸, åŸå§‹ DataFrame)
    """
    try:
        # ä½¿ç”¨ openpyxl æŸ¥æ‰¾æœ€ä½³ Sheet ç´¢å¼•
        target_idx, all_sheets = _find_best_sheet_index(excel_path)

        if not all_sheets:
            print(f"[è­¦å‘Š] Excel æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• Sheet")
            return {}, pd.DataFrame()

        print(f"  [Sheet åŒ¹é…] æ‰¾åˆ° {len(all_sheets)} ä¸ª Sheet: {all_sheets}")
        print(f"  [Sheet åŒ¹é…] é€‰æ‹©è¯»å–ç´¢å¼• {target_idx}: '{all_sheets[target_idx]}'")

        # ä½¿ç”¨ openpyxl å¼•æ“ï¼Œé€šè¿‡ç´¢å¼•åŠ è½½
        df = pd.read_excel(
            excel_path,
            sheet_name=target_idx,  # ä½¿ç”¨ç´¢å¼•è€Œéåç§°
            engine='openpyxl'
        )

        if df.empty:
            return {}, df

        # æ¸…æ´—åˆ—åï¼šå»æ‰ç©ºæ ¼ã€æ¢è¡Œç¬¦
        original_columns = list(df.columns)
        cleaned_columns = [_clean_column_name(col) for col in df.columns]
        df.columns = cleaned_columns

        # æ‰“å°åˆ—åæ˜ å°„ï¼ˆè°ƒè¯•ç”¨ï¼‰
        print(f"  [åˆ—åæ¸…æ´—] åŸå§‹ -> æ¸…æ´—å:")
        for orig, clean in zip(original_columns, cleaned_columns):
            if orig != clean:
                print(f"    '{orig}' -> '{clean}'")

        # è¿‡æ»¤æ‰å…¨é›¶è¡Œï¼Œè·å–æœ‰æ•ˆæ•°æ®
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) == 0:
            print(f"[è­¦å‘Š] Sheet ç´¢å¼• {target_idx} ä¸­æ²¡æœ‰æ•°å€¼åˆ—")
            return {}, df

        df_valid = df[df[numeric_cols].sum(axis=1) > 0]

        if df_valid.empty:
            # å°è¯•è¯»å–å…¶ä»– Sheetï¼ˆé€šè¿‡ç´¢å¼•ï¼‰
            for other_idx in range(len(all_sheets)):
                if other_idx == target_idx:
                    continue
                print(f"  [å›é€€] å°è¯•è¯»å– Sheet ç´¢å¼• {other_idx}: '{all_sheets[other_idx]}'")
                df_other = pd.read_excel(excel_path, sheet_name=other_idx, engine='openpyxl')
                # æ¸…æ´—åˆ—å
                df_other.columns = [_clean_column_name(col) for col in df_other.columns]
                numeric_cols_other = df_other.select_dtypes(include=['number']).columns
                if len(numeric_cols_other) > 0:
                    df_valid_other = df_other[df_other[numeric_cols_other].sum(axis=1) > 0]
                    if not df_valid_other.empty:
                        df = df_other
                        df_valid = df_valid_other
                        print(f"  [å›é€€] æˆåŠŸä»ç´¢å¼• {other_idx} è¯»å–åˆ°æ•°æ®")
                        break

        if df_valid.empty:
            return {}, df

        # å–æœ€å 5 è¡Œçš„ä¸­ä½æ•°
        last_rows = df_valid.tail(5)

        extracted = {}

        # æ„å»ºæ¸…æ´—åçš„åˆ—åæ˜ å°„
        cleaned_column_map = {_clean_column_name(k): v for k, v in EXCEL_COLUMN_MAP.items()}

        for clean_col in df.columns:
            if clean_col in cleaned_column_map:
                std_name = cleaned_column_map[clean_col]
                values = last_rows[clean_col].dropna()
                if len(values) > 0:
                    if values.dtype in ['int64', 'float64']:
                        extracted[std_name] = round(float(values.median()), 2)
                    else:
                        extracted[std_name] = str(values.iloc[-1])

        return extracted, df

    except Exception as e:
        print(f"[é”™è¯¯] è¯»å–ç”Ÿç†æµ‹è¯„ Excel å¤±è´¥: {e}")
        return {}, pd.DataFrame()


def extract_from_excel_psych(excel_path: str) -> Tuple[Dict[str, Any], pd.DataFrame]:
    """
    ä»å¿ƒç†æµ‹è¯„ Excel æ–‡ä»¶ä¸­æå–æ•°æ®

    Args:
        excel_path: Excel æ–‡ä»¶è·¯å¾„

    Returns:
        (æå–çš„æ•°æ®å­—å…¸, åŸå§‹ DataFrame)
    """
    try:
        df = pd.read_excel(excel_path)

        if df.empty:
            return {}, df

        # å–æœ€åä¸€è¡Œæ•°æ®
        last_row = df.iloc[-1]

        extracted = {}

        for excel_col, std_name in EXCEL_COLUMN_MAP.items():
            if excel_col in df.columns:
                value = last_row[excel_col]
                if pd.notna(value):
                    if isinstance(value, (int, float)):
                        extracted[std_name] = round(float(value), 2)
                    elif std_name in ['mood_state']:  # ä¿ç•™æ–‡æœ¬å­—æ®µ
                        extracted[std_name] = str(value)
                    else:
                        # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                        try:
                            extracted[std_name] = round(float(value), 2)
                        except (ValueError, TypeError):
                            extracted[std_name] = str(value)

        return extracted, df

    except Exception as e:
        print(f"[é”™è¯¯] è¯»å–å¿ƒç†æµ‹è¯„ Excel å¤±è´¥: {e}")
        return {}, pd.DataFrame()


def _extract_value_after_anchor(text: str, anchor: str, search_range: int = 200) -> Optional[float]:
    """
    å…³é”®è¯é”šç‚¹æ³•ï¼šå®šä½åˆ°å…³é”®è¯åï¼Œå‘åæœç´¢ç¬¬ä¸€ä¸ªæµ®ç‚¹æ•°

    Args:
        text: å…¨æ–‡æœ¬
        anchor: é”šç‚¹å…³é”®è¯
        search_range: å‘åæœç´¢çš„å­—ç¬¦èŒƒå›´

    Returns:
        æ‰¾åˆ°çš„æµ®ç‚¹æ•°ï¼Œæˆ– None
    """
    # æŸ¥æ‰¾é”šç‚¹ä½ç½®
    anchor_pos = text.find(anchor)
    if anchor_pos == -1:
        # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå¿½ç•¥ç©ºæ ¼ï¼‰
        anchor_no_space = anchor.replace(' ', '')
        text_no_space = text.replace(' ', '').replace('\n', '')
        anchor_pos = text_no_space.find(anchor_no_space)
        if anchor_pos == -1:
            return None
        # åœ¨åŸæ–‡ä¸­æ‰¾åˆ°å¯¹åº”ä½ç½®ï¼ˆè¿‘ä¼¼ï¼‰
        anchor_pos = text.find(anchor[0], max(0, anchor_pos - 10))

    if anchor_pos == -1:
        return None

    # å‘åæœç´¢ç¬¬ä¸€ä¸ªæµ®ç‚¹æ•°
    search_text = text[anchor_pos:anchor_pos + search_range]
    # åŒ¹é…æ•´æ•°æˆ–æµ®ç‚¹æ•°
    match = re.search(r'(\d+\.?\d*)', search_text)
    if match:
        try:
            return float(match.group(1))
        except ValueError:
            return None
    return None


def extract_from_pdf_with_regex(pdf_path: str) -> Tuple[Dict[str, Any], str]:
    """
    ä» PDF ä¸­ä½¿ç”¨å…³é”®è¯é”šç‚¹æ³•æå–ç„¦è™‘åˆ†æ•°å’Œ SCL-90 å› å­åˆ†

    æ”¹è¿›ï¼š
    1. ä¸ä½¿ç”¨ extract_tableï¼Œæ”¹ç”¨å…¨æ–‡æœ¬æœç´¢
    2. å…ˆå®šä½å…³é”®è¯é”šç‚¹ï¼Œå‘åæœç´¢ç¬¬ä¸€ä¸ªæµ®ç‚¹æ•°
    3. å¦‚æœ raw_text ä¸ºç©ºï¼Œæ˜ç¡®æç¤ºæ˜¯æ‰«æä»¶

    Args:
        pdf_path: PDF æ–‡ä»¶è·¯å¾„

    Returns:
        (æå–çš„æ•°æ®å­—å…¸, åŸå§‹æ–‡æœ¬)
    """
    raw_text = ""
    extracted = {}

    print(f"  [PDF è§£æ] å¼€å§‹å…¨æ–‡æœ¬æå–ï¼ˆä¸ä½¿ç”¨ extract_tableï¼‰...")

    # å°è¯•æ–¹æ³•1ï¼špdfplumber ç›´æ¥æå–æ–‡æœ¬ï¼ˆä¸ä½¿ç”¨ extract_tableï¼‰
    try:
        import pdfplumber
        with pdfplumber.open(pdf_path) as pdf:
            for i, page in enumerate(pdf.pages):
                # åªæå–æ–‡æœ¬ï¼Œä¸æå–è¡¨æ ¼
                text = page.extract_text()
                if text:
                    raw_text += text + "\n"
                    print(f"    ç¬¬ {i+1} é¡µ: æå–åˆ° {len(text)} å­—ç¬¦")
    except Exception as e:
        print(f"  [è­¦å‘Š] pdfplumber æå–å¤±è´¥: {e}")

    # å¦‚æœ pdfplumber æ²¡æœ‰æå–åˆ°æ–‡æœ¬ï¼Œå°è¯• PyMuPDF
    if not raw_text.strip():
        print(f"  [å›é€€] pdfplumber æ— æ–‡æœ¬ï¼Œå°è¯• PyMuPDF...")
        try:
            import fitz  # PyMuPDF
            doc = fitz.open(pdf_path)
            for i, page in enumerate(doc):
                text = page.get_text()
                if text:
                    raw_text += text + "\n"
                    print(f"    ç¬¬ {i+1} é¡µ: æå–åˆ° {len(text)} å­—ç¬¦")
            doc.close()
        except Exception as e:
            print(f"  [è­¦å‘Š] PyMuPDF æå–å¤±è´¥: {e}")

    # å¦‚æœä»ç„¶æ²¡æœ‰æ–‡æœ¬ï¼Œæ˜ç¡®æç¤ºæ˜¯æ‰«æä»¶
    if not raw_text.strip():
        print(f"  [è­¦å‘Š] âš ï¸ PDF æ— æ–‡æœ¬å±‚ï¼Œè¯·ç¡®è®¤æ˜¯å¦ä¸ºæ‰«æä»¶")
        print(f"  [æç¤º] æ‰«æä»¶éœ€è¦ OCR æ”¯æŒï¼Œè¯·å®‰è£… pytesseract å’Œ pdf2image")

        # å°è¯• OCRï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            raw_text = _extract_text_with_ocr(pdf_path)
            if raw_text.strip():
                print(f"  [OCR] æˆåŠŸæå– {len(raw_text)} å­—ç¬¦")
        except Exception as e:
            print(f"  [è­¦å‘Š] OCR æå–å¤±è´¥: {e}")

        if not raw_text.strip():
            return {}, ""

    # ä½¿ç”¨å…³é”®è¯é”šç‚¹æ³•æå–æ•°æ®
    print(f"  [PDF è§£æ] ä½¿ç”¨å…³é”®è¯é”šç‚¹æ³•æœç´¢æ•°æ®...")

    # å…³é”®è¯é”šç‚¹é…ç½®ï¼š(æ ‡å‡†å, [é”šç‚¹å…³é”®è¯åˆ—è¡¨])
    anchor_config = [
        # å¿ƒç†å¥åº·æŠ¥å‘Šé”šç‚¹
        ("report_title", ["å¿ƒç†å¥åº·æµ‹è¯„ä¸ªäººæŠ¥å‘Š", "å¿ƒç†å¥åº·æµ‹è¯„æŠ¥å‘Š", "ä¸ªäººæŠ¥å‘Š"]),

        # ç„¦è™‘ç›¸å…³
        ("anxiety_score", ["ç„¦è™‘åˆ†æ•°", "ç„¦è™‘å¾—åˆ†", "ç„¦è™‘è¯„åˆ†", "SASåˆ†æ•°", "SASå¾—åˆ†", "ç„¦è™‘è‡ªè¯„", "ç„¦è™‘"]),

        # æŠ‘éƒç›¸å…³
        ("depression_score", ["æŠ‘éƒåˆ†æ•°", "æŠ‘éƒå¾—åˆ†", "æŠ‘éƒè¯„åˆ†", "SDSåˆ†æ•°", "SDSå¾—åˆ†", "æŠ‘éƒè‡ªè¯„", "æŠ‘éƒ"]),

        # å‹åŠ›ç›¸å…³
        ("stress_index", ["å‹åŠ›æŒ‡æ•°", "å‹åŠ›åˆ†æ•°", "å‹åŠ›å€¼", "å¿ƒç†å‹åŠ›"]),

        # SCL-90 å› å­åˆ†
        ("scl90_total", ["SCL-90æ€»åˆ†", "SCL90æ€»åˆ†", "ç—‡çŠ¶è‡ªè¯„æ€»åˆ†", "æ€»å‡åˆ†"]),
        ("scl90_somatization", ["èº¯ä½“åŒ–", "èº¯ä½“ä¸é€‚"]),
        ("scl90_obsessive", ["å¼ºè¿«ç—‡çŠ¶", "å¼ºè¿«"]),
        ("scl90_interpersonal", ["äººé™…å…³ç³»æ•æ„Ÿ", "äººé™…æ•æ„Ÿ", "äººé™…å…³ç³»"]),
        ("scl90_depression", ["æŠ‘éƒå› å­", "æŠ‘éƒç—‡çŠ¶"]),
        ("scl90_anxiety", ["ç„¦è™‘å› å­", "ç„¦è™‘ç—‡çŠ¶"]),
        ("scl90_hostility", ["æ•Œå¯¹", "æ•Œæ„"]),
        ("scl90_phobic", ["ææ€–", "ææƒ§"]),
        ("scl90_paranoid", ["åæ‰§", "å¦„æƒ³"]),
        ("scl90_psychoticism", ["ç²¾ç¥ç—…æ€§", "ç²¾ç¥è´¨"]),
    ]

    for std_name, anchors in anchor_config:
        if std_name == "report_title":
            # åªæ£€æŸ¥æŠ¥å‘Šæ ‡é¢˜æ˜¯å¦å­˜åœ¨
            for anchor in anchors:
                if anchor in raw_text:
                    print(f"    [é”šç‚¹] æ‰¾åˆ°æŠ¥å‘Šæ ‡é¢˜: '{anchor}'")
                    break
            continue

        # å°è¯•æ¯ä¸ªé”šç‚¹
        for anchor in anchors:
            value = _extract_value_after_anchor(raw_text, anchor)
            if value is not None:
                extracted[std_name] = value
                print(f"    [é”šç‚¹] {std_name}: é€šè¿‡ '{anchor}' æ‰¾åˆ°å€¼ {value}")
                break

    # å¦‚æœé”šç‚¹æ³•æ²¡æ‰¾åˆ°ï¼Œå›é€€åˆ°æ­£åˆ™åŒ¹é…
    if not extracted:
        print(f"  [å›é€€] é”šç‚¹æ³•æœªåŒ¹é…ï¼Œå°è¯•æ­£åˆ™è¡¨è¾¾å¼...")
        psych_patterns = {
            "anxiety_score": REGEX_PATTERNS["anxiety_score"],
            "depression_score": REGEX_PATTERNS["depression_score"],
            "stress_index": REGEX_PATTERNS["stress_index"],
            "scl90_total": REGEX_PATTERNS["scl90_total"],
            "scl90_somatization": REGEX_PATTERNS["scl90_somatization"],
            "scl90_obsessive": REGEX_PATTERNS["scl90_obsessive"],
            "scl90_interpersonal": REGEX_PATTERNS["scl90_interpersonal"],
            "scl90_depression": REGEX_PATTERNS["scl90_depression"],
            "scl90_anxiety": REGEX_PATTERNS["scl90_anxiety"],
            "scl90_hostility": REGEX_PATTERNS["scl90_hostility"],
            "scl90_phobic": REGEX_PATTERNS["scl90_phobic"],
            "scl90_paranoid": REGEX_PATTERNS["scl90_paranoid"],
            "scl90_psychoticism": REGEX_PATTERNS["scl90_psychoticism"],
        }

        for key, pattern in psych_patterns.items():
            if key not in extracted:
                match = re.search(pattern, raw_text, re.IGNORECASE)
                if match:
                    try:
                        value = float(match.group(1))
                        extracted[key] = value
                        print(f"    [æ­£åˆ™] {key}: {value}")
                    except (ValueError, IndexError):
                        pass

    if not extracted:
        print(f"  [ç»“æœ] æœªèƒ½ä» PDF ä¸­æå–åˆ°å¿ƒç†æ•°æ®")
    else:
        print(f"  [ç»“æœ] æˆåŠŸæå– {len(extracted)} é¡¹å¿ƒç†æŒ‡æ ‡")

    return extracted, raw_text


def _extract_text_with_ocr(pdf_path: str) -> str:
    """
    ä½¿ç”¨ OCR ä»æ‰«æä»¶ PDF æå–æ–‡æœ¬

    éœ€è¦å®‰è£…: pip install pytesseract pdf2image
    ä»¥åŠç³»ç»Ÿå®‰è£… Tesseract-OCR
    """
    try:
        from pdf2image import convert_from_path
        import pytesseract

        # è½¬æ¢ PDF ä¸ºå›¾ç‰‡
        images = convert_from_path(pdf_path, dpi=200)

        all_text = []
        for i, image in enumerate(images):
            # ä½¿ç”¨ä¸­æ–‡+è‹±æ–‡è¯†åˆ«
            text = pytesseract.image_to_string(image, lang='chi_sim+eng')
            all_text.append(text)

        return "\n".join(all_text)

    except ImportError:
        print("[æç¤º] OCR éœ€è¦å®‰è£… pytesseract å’Œ pdf2image")
        print("       pip install pytesseract pdf2image")
        print("       åŒæ—¶éœ€è¦ç³»ç»Ÿå®‰è£… Tesseract-OCR")
        return ""
    except Exception as e:
        print(f"[é”™è¯¯] OCR å¤„ç†å¤±è´¥: {e}")
        return ""


def extract_health_data(
    data_dir: str,
    user_id: str = None,
    prefer_latest: bool = True
) -> ExtractionResult:
    """
    æå–å¥åº·æ•°æ®çš„ä¸»å‡½æ•°

    ä¼˜å…ˆçº§ç­–ç•¥ï¼š
    1. ä¼˜å…ˆä» Excel è¯»å–ç”Ÿç†æŒ‡æ ‡
    2. PDF ä»…ç”¨äºæå–ç„¦è™‘åˆ†æ•°å’Œ SCL-90 å› å­åˆ†
    3. å¼‚å¸¸å›é€€ï¼šè§£æå¤±è´¥æ—¶ç»™å‡ºæ˜ç¡®æç¤º

    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼ˆå¦‚ data/raw/ï¼‰
        user_id: å¯é€‰çš„ç”¨æˆ· ID ç­›é€‰
        prefer_latest: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨æœ€æ–°æ–‡ä»¶

    Returns:
        ExtractionResult å¯¹è±¡
    """
    result = ExtractionResult()

    # 1. æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
    files = find_matching_files(data_dir, user_id)

    print(f"\n{'='*60}")
    print("å¥åº·æ•°æ®æå–å¼€å§‹")
    print(f"{'='*60}")
    print(f"æ•°æ®ç›®å½•: {data_dir}")
    print(f"ç”¨æˆ· ID: {user_id or 'å…¨éƒ¨'}")
    print(f"æ‰¾åˆ°çš„æ–‡ä»¶:")
    print(f"  - ç”Ÿç†æµ‹è¯„ Excel: {len(files['physio_excel'])} ä¸ª")
    print(f"  - å¿ƒç†æµ‹è¯„ Excel: {len(files['psych_excel'])} ä¸ª")
    print(f"  - PDF æŠ¥å‘Š: {len(files['pdf'])} ä¸ª")

    # 2. ä¼˜å…ˆä» Excel è¯»å–ç”Ÿç†æ•°æ®
    if files['physio_excel']:
        physio_file = files['physio_excel'][0]  # æœ€æ–°çš„æ–‡ä»¶
        print(f"\n[ç”Ÿç†æ•°æ®] è¯»å– Excel: {physio_file.name}")

        physio_data, raw_df = extract_from_excel_physio(str(physio_file))

        if physio_data:
            result.physio_data = physio_data
            result.physio_source = str(physio_file)
            result.physio_success = True
            result.raw_excel_physio = raw_df
            print(f"  -> æˆåŠŸæå– {len(physio_data)} é¡¹ç”Ÿç†æŒ‡æ ‡")
            for k, v in physio_data.items():
                print(f"     {k}: {v}")
        else:
            result.warnings.append("ç”Ÿç†æµ‹è¯„ Excel æ–‡ä»¶è¯»å–å¤±è´¥æˆ–æ— æœ‰æ•ˆæ•°æ®")
            result.failed_fields.append("physio_excel")
    else:
        result.warnings.append("æœªæ‰¾åˆ°ç”Ÿç†æµ‹è¯„ Excel æ–‡ä»¶")
        result.failed_fields.append("physio_excel")

    # 3. ä»å¿ƒç†æµ‹è¯„ Excel è¯»å–åŸºç¡€å¿ƒç†æ•°æ®
    if files['psych_excel']:
        psych_file = files['psych_excel'][0]
        print(f"\n[å¿ƒç†æ•°æ®] è¯»å– Excel: {psych_file.name}")

        psych_excel_data, raw_df = extract_from_excel_psych(str(psych_file))

        if psych_excel_data:
            result.psych_data.update(psych_excel_data)
            result.psych_source = str(psych_file)
            result.raw_excel_psych = raw_df
            print(f"  -> æˆåŠŸæå– {len(psych_excel_data)} é¡¹å¿ƒç†æŒ‡æ ‡")
            for k, v in psych_excel_data.items():
                print(f"     {k}: {v}")

    # 4. ä» PDF æå–ç„¦è™‘åˆ†æ•°å’Œ SCL-90ï¼ˆä½œä¸ºè¡¥å……ï¼‰
    if files['pdf']:
        pdf_file = files['pdf'][0]
        print(f"\n[PDF è§£æ] å°è¯•æå–ç„¦è™‘åˆ†æ•°å’Œ SCL-90: {pdf_file.name}")

        pdf_data, raw_text = extract_from_pdf_with_regex(str(pdf_file))
        result.raw_pdf_text = raw_text

        if pdf_data:
            # PDF æ•°æ®ä½œä¸ºè¡¥å……ï¼Œä¸è¦†ç›–å·²æœ‰æ•°æ®
            for k, v in pdf_data.items():
                if k not in result.psych_data:
                    result.psych_data[k] = v
            result.psych_success = True
            print(f"  -> æˆåŠŸæå– {len(pdf_data)} é¡¹å¿ƒç†æŒ‡æ ‡")
            for k, v in pdf_data.items():
                print(f"     {k}: {v}")
        else:
            if not raw_text.strip():
                msg = "PDF ä¸ºæ‰«æä»¶æ ¼å¼ï¼Œæ–‡æœ¬æå–å¤±è´¥ï¼ˆéœ€è¦ OCR æ”¯æŒï¼‰"
            else:
                msg = "PDF æ–‡æœ¬ä¸­æœªåŒ¹é…åˆ°ç„¦è™‘åˆ†æ•°æˆ– SCL-90 å› å­åˆ†"
            result.warnings.append(msg)
            print(f"  -> è­¦å‘Š: {msg}")

    # 5. æ£€æŸ¥å¿ƒç†æ•°æ®æ˜¯å¦æˆåŠŸ
    if result.psych_data:
        result.psych_success = True
    else:
        result.failed_fields.append("psych_data")

    # 6. ç”Ÿæˆå¼‚å¸¸å›é€€æç¤º
    print(f"\n{'='*60}")
    print("æå–ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    print(f"ç”Ÿç†æ•°æ®: {'æˆåŠŸ' if result.physio_success else 'å¤±è´¥'} (æ¥æº: {result.physio_source or 'æ— '})")
    print(f"å¿ƒç†æ•°æ®: {'æˆåŠŸ' if result.psych_success else 'å¤±è´¥'} (æ¥æº: {result.psych_source or 'æ— '})")

    if result.warnings:
        print(f"\nè­¦å‘Šä¿¡æ¯:")
        for w in result.warnings:
            print(f"  - {w}")

    if result.failed_fields:
        print(f"\nè§£æå¤±è´¥æç¤º:")
        if "physio_excel" in result.failed_fields:
            print("  - ç”Ÿç†æ•°æ®æå–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨ç¡®è®¤")
        if "psych_data" in result.failed_fields:
            print("  - å¿ƒç†æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨ç¡®è®¤")

    return result


def generate_fallback_message(result: ExtractionResult) -> str:
    """
    ç”Ÿæˆå¼‚å¸¸å›é€€æç¤ºä¿¡æ¯

    Args:
        result: æå–ç»“æœ

    Returns:
        æç¤ºä¿¡æ¯å­—ç¬¦ä¸²
    """
    messages = []

    if result.physio_success:
        messages.append(f"ç”Ÿç†æ•°æ®æå–è‡ª Excel ({Path(result.physio_source).name})")
    else:
        messages.append("ç”Ÿç†æ•°æ®æå–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨ç¡®è®¤")

    if result.psych_success:
        if result.psych_source:
            messages.append(f"å¿ƒç†æ•°æ®æå–è‡ª {Path(result.psych_source).name}")
    else:
        messages.append("å¿ƒç†æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨ç¡®è®¤")

    if result.warnings:
        messages.append(f"æ³¨æ„äº‹é¡¹: {'; '.join(result.warnings)}")

    return "\n".join(messages)


# ============ çœ‹æ¿é™çº§ç­–ç•¥ ============

@dataclass
class DashboardData:
    """çœ‹æ¿æ•°æ®ç»“æ„"""
    # çœ‹æ¿ç±»å‹ï¼š'full' å®Œæ•´çœ‹æ¿, 'partial' åˆæ­¥çœ‹æ¿ï¼ˆä»…ç”Ÿç†æ•°æ®ï¼‰
    dashboard_type: str = "full"

    # ç”Ÿç†æŒ‡æ ‡çœ‹æ¿
    hrv_metrics: Dict[str, Any] = field(default_factory=dict)
    heart_rate_metrics: Dict[str, Any] = field(default_factory=dict)

    # å¿ƒç†æŒ‡æ ‡çœ‹æ¿ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
    psych_metrics: Dict[str, Any] = field(default_factory=dict)

    # ç»¼åˆè¯„ä¼°
    overall_status: str = ""
    risk_level: str = ""  # 'low', 'medium', 'high'

    # è­¦å‘Šå’Œæç¤º
    notices: List[str] = field(default_factory=list)

    # æ•°æ®æ¥æº
    data_sources: List[str] = field(default_factory=list)


def _assess_hrv_status(physio_data: Dict[str, Any]) -> Tuple[str, str]:
    """
    æ ¹æ® HRV æŒ‡æ ‡è¯„ä¼°å¥åº·çŠ¶æ€

    Returns:
        (çŠ¶æ€æè¿°, é£é™©ç­‰çº§)
    """
    sdnn = physio_data.get('SDNN', 0)
    rmssd = physio_data.get('RMSSD', 0)
    lf_hf = physio_data.get('LF_HF_ratio', 1.0)

    # è¯„ä¼°é€»è¾‘
    if sdnn >= 100 and rmssd >= 40:
        return "HRV æŒ‡æ ‡è‰¯å¥½ï¼Œè‡ªä¸»ç¥ç»è°ƒèŠ‚åŠŸèƒ½æ­£å¸¸", "low"
    elif sdnn >= 50 and rmssd >= 20:
        return "HRV æŒ‡æ ‡ä¸­ç­‰ï¼Œå»ºè®®é€‚å½“æ”¾æ¾", "medium"
    else:
        return "HRV æŒ‡æ ‡åä½ï¼Œå»ºè®®å…³æ³¨å‹åŠ›ç®¡ç†", "high"


def _assess_heart_rate_status(physio_data: Dict[str, Any]) -> str:
    """æ ¹æ®å¿ƒç‡æŒ‡æ ‡è¯„ä¼°çŠ¶æ€"""
    hr = physio_data.get('heart_rate', 0)
    hr_max = physio_data.get('heart_rate_max', 0)
    hr_min = physio_data.get('heart_rate_min', 0)

    if 60 <= hr <= 100:
        return f"å¿ƒç‡æ­£å¸¸ ({hr} bpm)"
    elif hr < 60:
        return f"å¿ƒç‡åä½ ({hr} bpm)ï¼Œå¯èƒ½ä¸ºè¿åŠ¨å‘˜å¿ƒè„æˆ–éœ€å…³æ³¨"
    else:
        return f"å¿ƒç‡åé«˜ ({hr} bpm)ï¼Œå»ºè®®æ”¾æ¾ä¼‘æ¯"


def generate_dashboard(result: ExtractionResult) -> DashboardData:
    """
    ç”Ÿæˆå¥åº·çœ‹æ¿

    é™çº§ç­–ç•¥ï¼š
    - å¦‚æœç”Ÿç†å’Œå¿ƒç†æ•°æ®éƒ½æœ‰ -> ç”Ÿæˆå®Œæ•´çœ‹æ¿
    - å¦‚æœåªæœ‰ç”Ÿç†æ•°æ® -> ç”Ÿæˆåˆæ­¥çœ‹æ¿ï¼Œæ ‡æ³¨å¿ƒç†æ•°æ®ç¼ºå¤±
    - å¦‚æœç”Ÿç†æ•°æ®ä¹Ÿæ²¡æœ‰ -> è¿”å›ç©ºçœ‹æ¿ï¼Œæç¤ºæ•°æ®ç¼ºå¤±

    Args:
        result: æ•°æ®æå–ç»“æœ

    Returns:
        DashboardData çœ‹æ¿æ•°æ®
    """
    dashboard = DashboardData()

    # æƒ…å†µ 1ï¼šå®Œå…¨æ²¡æœ‰æ•°æ®
    if not result.physio_success and not result.psych_success:
        dashboard.dashboard_type = "empty"
        dashboard.overall_status = "æ•°æ®æå–å¤±è´¥"
        dashboard.risk_level = "unknown"
        dashboard.notices.append("ç”Ÿç†æ•°æ®å’Œå¿ƒç†æ•°æ®å‡æå–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨ç¡®è®¤åŸå§‹æ–‡ä»¶")
        return dashboard

    # æƒ…å†µ 2ï¼šåªæœ‰ç”Ÿç†æ•°æ®ï¼ˆé™çº§æ¨¡å¼ï¼‰
    if result.physio_success and not result.psych_success:
        dashboard.dashboard_type = "partial"
        dashboard.notices.append("âš ï¸ å¿ƒç†æ•°æ®ç¼ºå¤±ï¼Œè¯·å‚è€ƒ PDF æŠ¥å‘Šæ˜ç»†")
        dashboard.notices.append("å½“å‰ä¸ºã€åˆæ­¥çœ‹æ¿ã€‘ï¼Œä»…å±•ç¤ºç”Ÿç†æŒ‡æ ‡")

    # æƒ…å†µ 3ï¼šå®Œæ•´æ•°æ®
    elif result.physio_success and result.psych_success:
        dashboard.dashboard_type = "full"

    # å¡«å……ç”Ÿç†æ•°æ®
    if result.physio_success:
        physio = result.physio_data

        # HRV æŒ‡æ ‡
        dashboard.hrv_metrics = {
            "SDNN": physio.get('SDNN', '--'),
            "RMSSD": physio.get('RMSSD', '--'),
            "pNN50": physio.get('pNN50', '--'),
            "LF": physio.get('LF', '--'),
            "HF": physio.get('HF', '--'),
            "LF/HF": physio.get('LF_HF_ratio', '--'),
        }

        # å¿ƒç‡æŒ‡æ ‡
        dashboard.heart_rate_metrics = {
            "å¹³å‡å¿ƒç‡": physio.get('heart_rate', '--'),
            "æœ€é«˜å¿ƒç‡": physio.get('heart_rate_max', '--'),
            "æœ€ä½å¿ƒç‡": physio.get('heart_rate_min', '--'),
            "å¿ƒç‡æ ‡å‡†å·®": physio.get('heart_rate_std', '--'),
        }

        # è¯„ä¼°çŠ¶æ€
        hrv_status, risk = _assess_hrv_status(physio)
        hr_status = _assess_heart_rate_status(physio)

        dashboard.overall_status = f"{hrv_status}ï¼›{hr_status}"
        dashboard.risk_level = risk

        dashboard.data_sources.append(f"ç”Ÿç†æ•°æ®: {Path(result.physio_source).name}")

    # å¡«å……å¿ƒç†æ•°æ®
    if result.psych_success:
        psych = result.psych_data

        dashboard.psych_metrics = {
            "å‹åŠ›æŒ‡æ•°": psych.get('stress_index', '--'),
            "ç–²åŠ³æŒ‡æ•°": psych.get('fatigue_index', '--'),
            "ç²¾åŠ›å€¼": psych.get('energy', '--'),
            "æƒ…ç»ªå€¼": psych.get('mood', '--'),
            "æƒ…ç»ªçŠ¶æ€": psych.get('mood_state', '--'),
            "ç„¦è™‘è¯„åˆ†": psych.get('anxiety_score', '--'),
            "æŠ‘éƒè¯„åˆ†": psych.get('depression_score', '--'),
        }

        # SCL-90 å› å­åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
        scl90_keys = [k for k in psych.keys() if k.startswith('scl90_')]
        if scl90_keys:
            dashboard.psych_metrics["SCL-90 å› å­"] = {
                k.replace('scl90_', ''): psych[k] for k in scl90_keys
            }

        if result.psych_source:
            dashboard.data_sources.append(f"å¿ƒç†æ•°æ®: {Path(result.psych_source).name}")

    return dashboard


def format_dashboard_text(dashboard: DashboardData) -> str:
    """
    å°†çœ‹æ¿æ•°æ®æ ¼å¼åŒ–ä¸ºæ–‡æœ¬è¾“å‡º

    Args:
        dashboard: çœ‹æ¿æ•°æ®

    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬å­—ç¬¦ä¸²
    """
    lines = []

    # æ ‡é¢˜
    if dashboard.dashboard_type == "full":
        lines.append("=" * 60)
        lines.append("        å¥åº·çŠ¶æ€çœ‹æ¿ - å®Œæ•´ç‰ˆ")
        lines.append("=" * 60)
    elif dashboard.dashboard_type == "partial":
        lines.append("=" * 60)
        lines.append("        å¥åº·çŠ¶æ€çœ‹æ¿ - åˆæ­¥ç‰ˆï¼ˆä»…ç”Ÿç†æ•°æ®ï¼‰")
        lines.append("=" * 60)
    else:
        lines.append("=" * 60)
        lines.append("        å¥åº·çŠ¶æ€çœ‹æ¿ - æ•°æ®ç¼ºå¤±")
        lines.append("=" * 60)

    # è­¦å‘Šä¿¡æ¯
    if dashboard.notices:
        lines.append("")
        for notice in dashboard.notices:
            lines.append(f"  {notice}")
        lines.append("")

    # ç»¼åˆè¯„ä¼°
    if dashboard.overall_status:
        lines.append("-" * 40)
        lines.append("ã€ç»¼åˆè¯„ä¼°ã€‘")
        lines.append(f"  {dashboard.overall_status}")
        risk_emoji = {"low": "ğŸŸ¢", "medium": "ğŸŸ¡", "high": "ğŸ”´", "unknown": "âšª"}
        lines.append(f"  é£é™©ç­‰çº§: {risk_emoji.get(dashboard.risk_level, 'âšª')} {dashboard.risk_level.upper()}")
        lines.append("")

    # HRV æŒ‡æ ‡
    if dashboard.hrv_metrics:
        lines.append("-" * 40)
        lines.append("ã€HRV å¿ƒç‡å˜å¼‚æ€§æŒ‡æ ‡ã€‘")
        for k, v in dashboard.hrv_metrics.items():
            unit = "ms" if k in ["SDNN", "RMSSD"] else ("%" if k == "pNN50" else "msÂ²" if k in ["LF", "HF"] else "")
            lines.append(f"  {k}: {v} {unit}".strip())
        lines.append("")

    # å¿ƒç‡æŒ‡æ ‡
    if dashboard.heart_rate_metrics:
        lines.append("-" * 40)
        lines.append("ã€å¿ƒç‡æŒ‡æ ‡ã€‘")
        for k, v in dashboard.heart_rate_metrics.items():
            unit = "bpm" if "å¿ƒç‡" in k else ""
            lines.append(f"  {k}: {v} {unit}".strip())
        lines.append("")

    # å¿ƒç†æŒ‡æ ‡
    if dashboard.psych_metrics:
        lines.append("-" * 40)
        lines.append("ã€å¿ƒç†çŠ¶æ€æŒ‡æ ‡ã€‘")
        for k, v in dashboard.psych_metrics.items():
            if k == "SCL-90 å› å­" and isinstance(v, dict):
                lines.append(f"  {k}:")
                for sk, sv in v.items():
                    lines.append(f"    - {sk}: {sv}")
            else:
                lines.append(f"  {k}: {v}")
        lines.append("")

    # æ•°æ®æ¥æº
    if dashboard.data_sources:
        lines.append("-" * 40)
        lines.append("ã€æ•°æ®æ¥æºã€‘")
        for src in dashboard.data_sources:
            lines.append(f"  â€¢ {src}")

    lines.append("=" * 60)

    return "\n".join(lines)


def extract_and_generate_dashboard(
    data_dir: str,
    user_id: str = None,
    print_output: bool = True
) -> Tuple[ExtractionResult, DashboardData]:
    """
    ä¸€ç«™å¼æå–æ•°æ®å¹¶ç”Ÿæˆçœ‹æ¿

    é™çº§ç­–ç•¥è‡ªåŠ¨å¤„ç†ï¼š
    - PDF æå–å¤±è´¥æ—¶ï¼Œä»…æ ¹æ® Excel ç”Ÿç†æŒ‡æ ‡ç”Ÿæˆåˆæ­¥çœ‹æ¿
    - ä¸ä¼šå› ä¸ºå¿ƒç†æ•°æ®ç¼ºå¤±è€Œä¸­æ–­æµç¨‹

    Args:
        data_dir: æ•°æ®ç›®å½•
        user_id: å¯é€‰ç”¨æˆ· ID
        print_output: æ˜¯å¦æ‰“å°çœ‹æ¿

    Returns:
        (æå–ç»“æœ, çœ‹æ¿æ•°æ®)
    """
    # æå–æ•°æ®
    result = extract_health_data(data_dir, user_id)

    # ç”Ÿæˆçœ‹æ¿
    dashboard = generate_dashboard(result)

    # æ‰“å°çœ‹æ¿
    if print_output:
        print("\n" + format_dashboard_text(dashboard))

    return result, dashboard


# ============ ä¸»å‡½æ•°å…¥å£ ============
if __name__ == "__main__":
    import argparse

    # ä»…åœ¨ç›´æ¥è¿è¡Œæ—¶ä¿®å¤ç¼–ç 
    _fix_windows_encoding()

    parser = argparse.ArgumentParser(description="å¥åº·æ•°æ®æå–ä¸çœ‹æ¿ç”Ÿæˆ")
    parser.add_argument("--data-dir", default=r"J:\xingjian-agent\MyOctopusProject\data\raw",
                        help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--user-id", default=None, help="ç”¨æˆ· ID ç­›é€‰")
    parser.add_argument("--dashboard", action="store_true", help="ç”Ÿæˆçœ‹æ¿")

    args = parser.parse_args()

    print("\n" + "="*70)
    print("å¥åº·æ•°æ®æå–ä¸çœ‹æ¿ç”Ÿæˆå·¥å…·")
    print("="*70)

    if args.dashboard:
        # ä½¿ç”¨ä¸€ç«™å¼å‡½æ•°ç”Ÿæˆçœ‹æ¿
        result, dashboard = extract_and_generate_dashboard(
            args.data_dir,
            args.user_id,
            print_output=True
        )
    else:
        # ä»…æå–æ•°æ®
        result = extract_health_data(args.data_dir, args.user_id)

        print("\n" + "="*60)
        print("æµ‹è¯•å®Œæˆ")
        print("="*60)

        # æ‰“å°å›é€€ä¿¡æ¯
        print("\nå›é€€ä¿¡æ¯:")
        print(generate_fallback_message(result))

        # æ‰“å°æœ€ç»ˆæ•°æ®
        print("\næœ€ç»ˆæå–çš„æ•°æ®:")
        print("ç”Ÿç†æ•°æ®:", result.physio_data)
        print("å¿ƒç†æ•°æ®:", result.psych_data)
