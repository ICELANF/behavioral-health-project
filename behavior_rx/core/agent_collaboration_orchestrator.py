"""
BehaviorOS â€” AgentCollaborationOrchestrator 4-Agent åä½œç¼–æ’å™¨
================================================================
ç®¡ç† 4 æ¬¾ä¸“å®¶ Agent ä¹‹é—´çš„åä½œå…³ç³»

æ‹“æ‰‘:
  è¡Œä¸ºæ•™ç»ƒ(ä¸Šæ¸¸) â†’ ä»£è°¢/å¿ƒè¡€ç®¡(é¢†åŸŸä¸‹æ¸¸) â† ä¾ä»æ€§(æ¨ªåˆ‡é¢)

åä½œåœºæ™¯:
  1. æ–°ç”¨æˆ·è¯„ä¼°:    Coach(ä¸»å¯¼) â†’ é¢†åŸŸAgent(å¾…å‘½) â†’ stageâ‰¥S3 äº¤æ¥
  2. ä»£è°¢å¼‚å¸¸:      Metabolic(ä¸»å¯¼) + Adherence(ååŒ) â†’ åˆå¹¶å¤„æ–¹
  3. è¿åŠ¨ææƒ§:      Coach(å‰ç½®è„±æ•) â†’ Cardiac(æ¥æ”¶) when stageâ†’S3
  4. å¤šç—…å…±ç®¡:      Metabolic + Cardiac(å¹¶è¡Œ) + Adherence(æ¨ªåˆ‡) â†’ å¤„æ–¹åˆå¹¶
  5. é˜¶æ®µå›é€€:      é¢†åŸŸAgent(æš‚åœ) â†’ Coach(ç´§æ€¥æ¥ç®¡) â†’ æ¢å¤åäº¤è¿˜
  6. å°±è¯Šå‡†å¤‡:      Adherence(ä¸»å¯¼) + é¢†åŸŸAgent(æ•°æ®æä¾›) â†’ å°±è¯Šå‡†å¤‡å¤„æ–¹
"""

from __future__ import annotations

import logging
import uuid
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

from ..core.rx_schemas import (
    ExpertAgentType,
    HandoffContext,
    HandoffRequest,
    HandoffType,
    RxContext,
    RxPrescriptionDTO,
)
from ..core.agent_handoff_service import AgentHandoffService
from ..agents.base_expert_agent import BaseExpertAgent, AgentResponse

logger = logging.getLogger(__name__)


# =====================================================================
# åä½œåœºæ™¯æšä¸¾
# =====================================================================

class CollaborationScenario(str, Enum):
    NEW_USER_ASSESSMENT = "new_user_assessment"
    GLUCOSE_ABNORMAL = "glucose_abnormal"
    EXERCISE_FEAR = "exercise_fear"
    MULTI_MORBIDITY = "multi_morbidity"
    STAGE_REGRESSION = "stage_regression"
    PRE_VISIT = "pre_visit"
    ADHERENCE_ALERT = "adherence_alert"
    DOMAIN_COORDINATION = "domain_coordination"


# =====================================================================
# åä½œå†³ç­–ç»“æœ
# =====================================================================

class CollaborationDecision:
    """åä½œç¼–æ’å†³ç­–ç»“æœ"""

    def __init__(
        self,
        scenario: CollaborationScenario,
        primary_agent: ExpertAgentType,
        secondary_agents: List[ExpertAgentType],
        merge_strategy: str = "primary_first",
        reason: str = "",
    ):
        self.scenario = scenario
        self.primary_agent = primary_agent
        self.secondary_agents = secondary_agents
        self.merge_strategy = merge_strategy
        self.reason = reason

    def to_dict(self) -> Dict[str, Any]:
        return {
            "scenario": self.scenario.value,
            "primary_agent": self.primary_agent.value,
            "secondary_agents": [a.value for a in self.secondary_agents],
            "merge_strategy": self.merge_strategy,
            "reason": self.reason,
        }


# =====================================================================
# åˆå¹¶åå¤„æ–¹
# =====================================================================

class MergedResponse:
    """å¤šAgentå¤„æ–¹åˆå¹¶ç»“æœ"""

    def __init__(
        self,
        primary: AgentResponse,
        overlays: List[AgentResponse],
        merged_message: str,
        merged_content: Dict[str, Any],
        collaboration: CollaborationDecision,
    ):
        self.primary = primary
        self.overlays = overlays
        self.merged_message = merged_message
        self.merged_content = merged_content
        self.collaboration = collaboration
        self.timestamp = datetime.utcnow()

    def to_dict(self) -> Dict[str, Any]:
        return {
            "primary_response": self.primary.to_dict(),
            "overlay_count": len(self.overlays),
            "merged_message": self.merged_message,
            "merged_content": self.merged_content,
            "collaboration": self.collaboration.to_dict(),
            "timestamp": self.timestamp.isoformat(),
        }


# =====================================================================
# AgentCollaborationOrchestrator â€” æ ¸å¿ƒç¼–æ’å™¨
# =====================================================================

class AgentCollaborationOrchestrator:
    """
    4-Agent åä½œç¼–æ’å™¨

    èŒè´£:
      1. åœºæ™¯è¯†åˆ« â€” æ ¹æ®ç”¨æˆ·ä¸Šä¸‹æ–‡åˆ¤æ–­åä½œåœºæ™¯
      2. Agent è·¯ç”± â€” ç¡®å®šä¸»å¯¼ Agent + è¾…åŠ© Agent åˆ—è¡¨
      3. å¤„æ–¹åˆå¹¶ â€” å¤š Agent å¤„æ–¹æ— å†²çªæ•´åˆ
      4. é˜¶æ®µå›é€€ç®¡ç† â€” æ£€æµ‹å¹¶å¤„ç†é˜¶æ®µå›é€€ç´§æ€¥äº‹ä»¶
      5. æ¨ªåˆ‡è§¦å‘ â€” è‡ªåŠ¨è§¦å‘ä¾ä»æ€§Agentæ¨ªåˆ‡ä»‹å…¥

    ä¸åš:
      - ä¸æ›¿ä»£ PolicyEngine åšå†²çªä»²è£
      - ä¸æ›¿ä»£å„ Agent åšé¢†åŸŸå†³ç­–
      - ä¸ç›´æ¥è°ƒç”¨ LLM (è¿™æ˜¯ MasterAgent çš„èŒè´£)
    """

    def __init__(
        self,
        agents: Optional[Dict[ExpertAgentType, BaseExpertAgent]] = None,
        handoff_service: Optional[AgentHandoffService] = None,
    ):
        self._agents = agents or {}
        self._handoff_service = handoff_service or AgentHandoffService()
        logger.info(
            f"CollaborationOrchestrator initialized with "
            f"{len(self._agents)} agents"
        )

    def register_agent(self, agent: BaseExpertAgent) -> None:
        """æ³¨å†Œä¸“å®¶Agent"""
        self._agents[agent.agent_type] = agent
        logger.info(f"Registered agent: {agent.agent_type.value}")

    # ---------------------------------------------------------------
    # åœºæ™¯è¯†åˆ«
    # ---------------------------------------------------------------

    def identify_scenario(
        self,
        context: RxContext,
        user_input: Dict[str, Any],
        current_agent: Optional[ExpertAgentType] = None,
    ) -> CollaborationDecision:
        """
        æ ¹æ®ä¸Šä¸‹æ–‡è¯†åˆ«åä½œåœºæ™¯, è¿”å›åä½œå†³ç­–

        å†³ç­–ä¼˜å…ˆçº§ (é«˜â†’ä½):
          1. é˜¶æ®µå›é€€ â†’ Coachç´§æ€¥æ¥ç®¡
          2. å®‰å…¨äº‹ä»¶ â†’ ç›¸å…³Agentæš‚åœ
          3. å¤šç—…å…±ç®¡ â†’ å¹¶è¡Œ+æ¨ªåˆ‡
          4. ä¾ä»è­¦æŠ¥ â†’ ä¾ä»Agentæ¨ªåˆ‡
          5. æ–°ç”¨æˆ·è¯„ä¼° â†’ Coachä¸»å¯¼
          6. é¢†åŸŸåä½œ â†’ æ­£å¸¸è·¯ç”±
        """
        stage = context.ttm_stage
        domain = context.domain_data
        barriers = context.active_barriers

        # Priority 1: é˜¶æ®µå›é€€
        if self._detect_stage_regression(context, user_input):
            return CollaborationDecision(
                scenario=CollaborationScenario.STAGE_REGRESSION,
                primary_agent=ExpertAgentType.BEHAVIOR_COACH,
                secondary_agents=[current_agent] if current_agent else [],
                merge_strategy="coach_override",
                reason=(
                    f"Stage regression detected: "
                    f"stability={context.stage_stability:.2f}, "
                    f"efficacy={context.self_efficacy:.2f}"
                ),
            )

        # Priority 2: ä¾ä»æ€§å±æœº
        med_missed = domain.get("medication_missed_7d", 0)
        visit_overdue = domain.get("visit_overdue_days", 0)
        if med_missed >= 4 or visit_overdue >= 30:
            primary = current_agent or ExpertAgentType.ADHERENCE_EXPERT
            secondaries = [ExpertAgentType.ADHERENCE_EXPERT]
            if current_agent == ExpertAgentType.ADHERENCE_EXPERT:
                secondaries = []
            return CollaborationDecision(
                scenario=CollaborationScenario.ADHERENCE_ALERT,
                primary_agent=primary,
                secondary_agents=secondaries,
                merge_strategy="adherence_overlay",
                reason=(
                    f"Adherence crisis: missed={med_missed}, "
                    f"overdue={visit_overdue}d"
                ),
            )

        # Priority 3: å¤šç—…å…±ç®¡ (åŒæ—¶æœ‰ä»£è°¢+å¿ƒè¡€ç®¡æ•°æ®)
        has_metabolic = any(
            k in domain for k in ["glucose", "hba1c", "bmi", "weight"]
        )
        has_cardiac = any(
            k in domain for k in ["cardiac_event_type", "rehab_phase",
                                   "exercise_fear_score"]
        )
        if has_metabolic and has_cardiac:
            return CollaborationDecision(
                scenario=CollaborationScenario.MULTI_MORBIDITY,
                primary_agent=(
                    current_agent or ExpertAgentType.METABOLIC_EXPERT
                ),
                secondary_agents=[
                    ExpertAgentType.CARDIAC_EXPERT,
                    ExpertAgentType.ADHERENCE_EXPERT,
                ],
                merge_strategy="parallel_merge",
                reason="Multi-morbidity: metabolic + cardiac data present",
            )

        # Priority 4: è¿åŠ¨ææƒ§ (å¿ƒè¡€ç®¡+ä½é˜¶æ®µ)
        fear_score = domain.get("exercise_fear_score", 0)
        if fear_score >= 25 and stage <= 2:
            return CollaborationDecision(
                scenario=CollaborationScenario.EXERCISE_FEAR,
                primary_agent=ExpertAgentType.BEHAVIOR_COACH,
                secondary_agents=[ExpertAgentType.CARDIAC_EXPERT],
                merge_strategy="coach_first_then_handoff",
                reason=f"Exercise fear={fear_score} + stage=S{stage} â†’ Coach first",
            )

        # Priority 5: å°±è¯Šå‡†å¤‡
        next_visit_days = domain.get("next_visit_in_days", 999)
        if next_visit_days <= 3:
            return CollaborationDecision(
                scenario=CollaborationScenario.PRE_VISIT,
                primary_agent=ExpertAgentType.ADHERENCE_EXPERT,
                secondary_agents=[
                    a for a in [
                        ExpertAgentType.METABOLIC_EXPERT,
                        ExpertAgentType.CARDIAC_EXPERT,
                    ]
                    if a != current_agent
                ],
                merge_strategy="adherence_lead",
                reason=f"Pre-visit: {next_visit_days}d until appointment",
            )

        # Priority 6: æ–°ç”¨æˆ·ä½é˜¶æ®µ
        if stage <= 2 and not current_agent:
            return CollaborationDecision(
                scenario=CollaborationScenario.NEW_USER_ASSESSMENT,
                primary_agent=ExpertAgentType.BEHAVIOR_COACH,
                secondary_agents=[],
                merge_strategy="single_agent",
                reason=f"New/low-stage user: S{stage}",
            )

        # Default: å½“å‰Agentå•ç‹¬å¤„ç†
        return CollaborationDecision(
            scenario=CollaborationScenario.DOMAIN_COORDINATION,
            primary_agent=current_agent or ExpertAgentType.BEHAVIOR_COACH,
            secondary_agents=self._detect_crosscut_needs(context, domain),
            merge_strategy="primary_first",
            reason="Standard domain processing",
        )

    # ---------------------------------------------------------------
    # ç¼–æ’æ‰§è¡Œ
    # ---------------------------------------------------------------

    async def orchestrate(
        self,
        user_input: Dict[str, Any],
        user_id: uuid.UUID,
        session_id: Optional[uuid.UUID] = None,
        current_agent: Optional[ExpertAgentType] = None,
        db=None,
    ) -> MergedResponse:
        """
        ç¼–æ’å¤šAgentåä½œå¹¶è¿”å›åˆå¹¶ç»“æœ

        æµç¨‹:
          1. æ„å»ºä¸Šä¸‹æ–‡ â†’ åœºæ™¯è¯†åˆ«
          2. è°ƒç”¨ä¸»Agent
          3. è°ƒç”¨è¾…åŠ©Agent(å¦‚æœ‰)
          4. åˆå¹¶å¤„æ–¹å’Œæ¶ˆæ¯
        """
        # Step 1: ä¸Šä¸‹æ–‡ & åœºæ™¯è¯†åˆ«
        profile = user_input.get("behavioral_profile", {})
        from ..core.rx_schemas import BigFiveProfile
        context = RxContext(
            user_id=user_id,
            session_id=session_id,
            ttm_stage=profile.get("ttm_stage", 0),
            stage_readiness=profile.get("stage_readiness", 0.5),
            stage_stability=profile.get("stage_stability", 0.5),
            personality=BigFiveProfile(**profile.get("bigfive", {})),
            capacity_score=profile.get("capacity_score", 0.5),
            self_efficacy=profile.get("self_efficacy", 0.5),
            domain_data={
                **user_input.get("device_data", {}),
                **user_input.get("domain_data", {}),
            },
            active_barriers=profile.get("active_barriers", []),
            recent_adherence=profile.get("recent_adherence", 0.5),
            risk_level=profile.get("risk_level", "normal"),
        )

        decision = self.identify_scenario(context, user_input, current_agent)
        logger.info(
            f"Collaboration scenario: {decision.scenario.value} "
            f"primary={decision.primary_agent.value} "
            f"secondaries={[a.value for a in decision.secondary_agents]}"
        )

        # Step 2: è°ƒç”¨ä¸»Agent
        primary_agent = self._agents.get(decision.primary_agent)
        if not primary_agent:
            raise ValueError(
                f"Primary agent {decision.primary_agent.value} not registered"
            )
        primary_response = await primary_agent.process(
            user_input, user_id, session_id, db
        )

        # Step 3: è°ƒç”¨è¾…åŠ©Agent
        overlay_responses = []
        for agent_type in decision.secondary_agents:
            agent = self._agents.get(agent_type)
            if agent:
                try:
                    overlay = await agent.process(
                        user_input, user_id, session_id, db
                    )
                    overlay_responses.append(overlay)
                except Exception as e:
                    logger.warning(
                        f"Secondary agent {agent_type.value} failed: {e}"
                    )

        # Step 4: åˆå¹¶
        merged_msg, merged_content = self._merge_responses(
            primary_response, overlay_responses, decision
        )

        return MergedResponse(
            primary=primary_response,
            overlays=overlay_responses,
            merged_message=merged_msg,
            merged_content=merged_content,
            collaboration=decision,
        )

    # ---------------------------------------------------------------
    # é˜¶æ®µå›é€€æ£€æµ‹
    # ---------------------------------------------------------------

    def _detect_stage_regression(
        self, context: RxContext, user_input: Dict[str, Any]
    ) -> bool:
        """
        æ£€æµ‹é˜¶æ®µå›é€€ä¿¡å·

        è§¦å‘æ¡ä»¶ (æ»¡è¶³ä»»ä¸€):
          - é˜¶æ®µç¨³å®šåº¦ < 0.3
          - è‡ªæˆ‘æ•ˆèƒ½æ€¥å‰§ä¸‹é™ (< 0.2)
          - ç”¨æˆ·æ–‡æœ¬å«æ”¾å¼ƒæ„å‘
        """
        if context.stage_stability < 0.3:
            return True
        if context.self_efficacy < 0.2 and context.ttm_stage >= 3:
            return True

        message = user_input.get("message", "").lower()
        regression_signals = [
            "ä¸æƒ³åšäº†", "æ”¾å¼ƒ", "æ²¡ç”¨", "åšä¸åˆ°", "å¤ªéš¾äº†",
            "give up", "quit", "can't do", "impossible",
            "ç®—äº†", "ä¸è¡Œäº†", "åšæŒä¸ä¸‹å»",
        ]
        return any(s in message for s in regression_signals)

    # ---------------------------------------------------------------
    # æ¨ªåˆ‡éœ€æ±‚æ£€æµ‹
    # ---------------------------------------------------------------

    def _detect_crosscut_needs(
        self,
        context: RxContext,
        domain: Dict[str, Any],
    ) -> List[ExpertAgentType]:
        """æ£€æµ‹æ˜¯å¦éœ€è¦ä¾ä»æ€§Agentæ¨ªåˆ‡ä»‹å…¥"""
        crosscuts = []
        med_missed = domain.get("medication_missed_7d", 0)
        visit_overdue = domain.get("visit_overdue_days", 0)

        if med_missed >= 2 or visit_overdue >= 7:
            crosscuts.append(ExpertAgentType.ADHERENCE_EXPERT)

        return crosscuts

    # ---------------------------------------------------------------
    # å¤„æ–¹åˆå¹¶
    # ---------------------------------------------------------------

    def _merge_responses(
        self,
        primary: AgentResponse,
        overlays: List[AgentResponse],
        decision: CollaborationDecision,
    ) -> Tuple[str, Dict[str, Any]]:
        """
        åˆå¹¶å¤šAgentå“åº”

        åˆå¹¶ç­–ç•¥:
          single_agent     â€” ç›´æ¥è¿”å›ä¸»Agent
          primary_first    â€” ä¸»Agentæ¶ˆæ¯ + è¾…åŠ©Agentå†…å®¹è¿½åŠ 
          adherence_overlay â€” ä¸»Agentæ¶ˆæ¯ + ä¾ä»æ€§æé†’è¿½åŠ 
          coach_override   â€” Coachæ¶ˆæ¯è¦†ç›–é¢†åŸŸAgent
          parallel_merge   â€” å¹¶è¡Œé¢†åŸŸå†…å®¹åˆå¹¶
          adherence_lead   â€” ä¾ä»Agentä¸»å¯¼, é¢†åŸŸAgentæ•°æ®æ±‡å…¥
        """
        strategy = decision.merge_strategy

        if not overlays or strategy == "single_agent":
            return primary.user_message, primary.domain_content

        if strategy == "coach_override":
            merged_content = {
                "coach": primary.domain_content,
                "suspended_domains": [
                    {
                        "agent": o.agent_type.value,
                        "status": "paused_for_regression",
                    }
                    for o in overlays
                ],
            }
            return primary.user_message, merged_content

        if strategy == "adherence_overlay":
            adherence_notes = []
            for o in overlays:
                if o.agent_type == ExpertAgentType.ADHERENCE_EXPERT:
                    adherence_notes.append(o.user_message)

            merged_msg = primary.user_message
            if adherence_notes:
                merged_msg += "\n\n---\nğŸ“‹ " + "\n".join(adherence_notes)

            merged_content = {
                "primary": primary.domain_content,
                "adherence_overlay": [o.domain_content for o in overlays],
            }
            return merged_msg, merged_content

        if strategy == "parallel_merge":
            merged_msg = primary.user_message
            for o in overlays:
                if o.user_message and o.agent_type != primary.agent_type:
                    # ä»…è¿½åŠ éé‡å¤çš„å…³é”®æé†’
                    short_note = o.user_message.split("\n")[0]
                    merged_msg += f"\n\nğŸ’¡ {short_note}"

            merged_content = {
                "primary": {
                    "agent": primary.agent_type.value,
                    "content": primary.domain_content,
                },
                "parallel": [
                    {
                        "agent": o.agent_type.value,
                        "content": o.domain_content,
                    }
                    for o in overlays
                ],
            }
            return merged_msg, merged_content

        # Default: primary_first / adherence_lead
        merged_content = {
            "primary": primary.domain_content,
            "supplements": [o.domain_content for o in overlays],
        }
        merged_msg = primary.user_message
        return merged_msg, merged_content

    # ---------------------------------------------------------------
    # Agent æ³¨å†ŒéªŒè¯
    # ---------------------------------------------------------------

    def get_registered_agents(self) -> List[str]:
        """è¿”å›å·²æ³¨å†Œçš„Agentåˆ—è¡¨"""
        return [a.value for a in self._agents.keys()]

    def is_fully_operational(self) -> bool:
        """æ£€æŸ¥4æ¬¾Agentæ˜¯å¦å…¨éƒ¨æ³¨å†Œ"""
        required = {
            ExpertAgentType.BEHAVIOR_COACH,
            ExpertAgentType.METABOLIC_EXPERT,
            ExpertAgentType.CARDIAC_EXPERT,
            ExpertAgentType.ADHERENCE_EXPERT,
        }
        return required.issubset(self._agents.keys())
