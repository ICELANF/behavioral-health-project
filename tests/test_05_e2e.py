"""
æµ‹è¯• 05 â€” ç«¯åˆ°ç«¯æµç¨‹
è¿è¡Œ: python -m pytest tests/test_05_e2e.py -v

å®Œæ•´æµç¨‹: æ–‡æ¡£ä¸Šä¼  â†’ è§£æ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ å…¥åº“ â†’ æ£€ç´¢ â†’ RAG å¢å¼º â†’ å‰ç«¯å±•ç¤ºæ ¼å¼

è¿™æ˜¯æœ€é‡è¦çš„é›†æˆæµ‹è¯•ï¼ŒéªŒè¯æ‰€æœ‰ç»„ä»¶ä¸²é€šã€‚
éœ€è¦: PostgreSQL + pgvector + Embedding æ¨¡å‹
"""
import sys, os, asyncio, unittest, tempfile, shutil
from unittest import IsolatedAsyncioTestCase

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))

DATABASE_URL = os.environ.get(
    "DATABASE_URL",
    "postgresql+asyncpg://postgres:postgres@localhost:5432/health_platform"
)


class TestEndToEndIngestAndRetrieve(IsolatedAsyncioTestCase):
    """
    ç«¯åˆ°ç«¯: æ–‡ä»¶ â†’ è§£æ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ å…¥åº“ â†’ æ£€ç´¢

    å®Œæ•´éªŒè¯ RAG v2 æœ¬åœ°ä¼˜å…ˆæœºåˆ¶ã€‚
    """

    @classmethod
    def setUpClass(cls):
        """å‡†å¤‡æµ‹è¯•æ–‡ä»¶å’ŒæœåŠ¡"""
        cls.tmpdir = tempfile.mkdtemp(prefix="test_e2e_")

        # åˆ›å»ºæµ‹è¯•çŸ¥è¯†æ–‡æ¡£ (ä¸­åŒ»ä½“è´¨)
        cls.test_doc_path = os.path.join(cls.tmpdir, "tcm_constitution.md")
        with open(cls.test_doc_path, "w", encoding="utf-8") as f:
            f.write("""# ä¸­åŒ»ä½“è´¨è¾¨è¯†æŒ‡å—

## ä¹ç§ä½“è´¨æ¦‚è¿°

ä¸­åŒ»å°†äººä½“ä½“è´¨åˆ†ä¸ºä¹ç§åŸºæœ¬ç±»å‹ï¼šå¹³å’Œè´¨ã€æ°”è™šè´¨ã€é˜³è™šè´¨ã€é˜´è™šè´¨ã€
ç—°æ¹¿è´¨ã€æ¹¿çƒ­è´¨ã€è¡€ç˜€è´¨ã€æ°”éƒè´¨ã€ç‰¹ç¦€è´¨ã€‚

æ¯ç§ä½“è´¨éƒ½æœ‰å…¶ç‹¬ç‰¹çš„ç”Ÿç†ç‰¹å¾ã€å¿ƒç†ç‰¹å¾å’Œé€‚å®œçš„è°ƒç†æ–¹æ³•ã€‚

## å¹³å’Œè´¨

### ç‰¹å¾
é˜´é˜³æ°”è¡€è°ƒå’Œï¼Œä½“æ€é€‚ä¸­ï¼Œé¢è‰²çº¢æ¶¦ï¼Œç²¾åŠ›å……æ²›ã€‚

### è°ƒç†å»ºè®®
é¥®é£Ÿå‡è¡¡ï¼Œé€‚é‡è¿åŠ¨ï¼Œä¿æŒå¿ƒæƒ…èˆ’ç•…ã€‚

## æ°”è™šè´¨

### ç‰¹å¾
å®¹æ˜“ç–²ä¹ï¼Œæ°”çŸ­ï¼Œè‡ªæ±—ï¼ŒèˆŒæ·¡çº¢ï¼Œè„‰å¼±ã€‚

### è°ƒç†å»ºè®®
è¡¥æ°”ä¸ºä¸»ï¼Œé€‚å®œé£Ÿç”¨é»„èŠªã€å…šå‚ç­‰è¡¥æ°”é£Ÿæã€‚
é¿å…è¿‡åº¦åŠ³ç´¯ï¼Œé€‚é‡è¿åŠ¨å¦‚å¤ªææ‹³ã€å…«æ®µé”¦ã€‚

## é˜³è™šè´¨

### ç‰¹å¾
ç•å¯’æ€•å†·ï¼Œæ‰‹è¶³ä¸æ¸©ï¼Œå–œçƒ­é¥®é£Ÿï¼ŒèˆŒæ·¡èƒ–å«©ã€‚

### è°ƒç†å»ºè®®
æ¸©é˜³æ•£å¯’ï¼Œé€‚å®œé£Ÿç”¨ç”Ÿå§œã€æ¡‚åœ†ã€ç¾Šè‚‰ç­‰æ¸©çƒ­é£Ÿæã€‚
æ³¨æ„ä¿æš–ï¼Œé¿å…å—å¯’ã€‚
""")

        # åˆ›å»ºç¬¬äºŒä¸ªæµ‹è¯•æ–‡æ¡£ (å¤§äº”äººæ ¼)
        cls.test_doc2_path = os.path.join(cls.tmpdir, "big_five.md")
        with open(cls.test_doc2_path, "w", encoding="utf-8") as f:
            f.write("""# å¤§äº”äººæ ¼ä¸å¥åº·å¹²é¢„

## å¼€æ”¾æ€§

é«˜å¼€æ”¾æ€§äººç¾¤å€¾å‘äºæ¥å—æ–°äº‹ç‰©ï¼Œå¯¹åˆ›æ–°çš„å¥åº·æ–¹æ¡ˆæ¥å—åº¦è¾ƒé«˜ã€‚
å»ºè®®æä¾›å¤šæ ·åŒ–çš„å¥åº·é€‰æ‹©ã€‚

## å°½è´£æ€§

é«˜å°½è´£æ€§äººç¾¤è‡ªå¾‹æ€§å¼ºï¼Œé€‚åˆç»“æ„åŒ–çš„å¥åº·ç®¡ç†è®¡åˆ’ã€‚
å¯ä»¥è®¾å®šæ˜ç¡®çš„é˜¶æ®µç›®æ ‡å’Œæ‰“å¡æœºåˆ¶ã€‚

## å¤–å‘æ€§

å¤–å‘æ€§é«˜çš„äººç¾¤é€‚åˆå›¢ä½“å¥åº·æ´»åŠ¨ï¼Œç¤¾äº¤æ”¯æŒæœ‰åŠ©äºå¥åº·è¡Œä¸ºç»´æŒã€‚
""")

        # æ£€æŸ¥ä¾èµ–
        try:
            from services.chunker import EmbeddingService
            cls.embedder = EmbeddingService()
            cls.embedding_available = True
        except Exception as e:
            cls.embedding_available = False
            cls.skip_reason = str(e)

    @classmethod
    def tearDownClass(cls):
        shutil.rmtree(cls.tmpdir, ignore_errors=True)

    async def asyncSetUp(self):
        if not self.embedding_available:
            self.skipTest(f"Embedding ä¸å¯ç”¨: {self.skip_reason}")

        from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
        from sqlalchemy.orm import sessionmaker

        url = DATABASE_URL
        if "asyncpg" not in url:
            url = url.replace("postgresql://", "postgresql+asyncpg://")
        self.engine = create_async_engine(url, echo=False)
        self.SessionLocal = sessionmaker(self.engine, class_=AsyncSession, expire_on_commit=False)
        self._cleanup_doc_ids = []

    async def asyncTearDown(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        if self._cleanup_doc_ids:
            from sqlalchemy import text
            async with self.engine.connect() as conn:
                for doc_id in self._cleanup_doc_ids:
                    await conn.execute(text("DELETE FROM knowledge_citations WHERE document_id = :id"), {"id": doc_id})
                    await conn.execute(text("DELETE FROM knowledge_chunks WHERE document_id = :id"), {"id": doc_id})
                    await conn.execute(text("DELETE FROM knowledge_documents WHERE id = :id"), {"id": doc_id})
                await conn.commit()
        if hasattr(self, 'engine'):
            await self.engine.dispose()

    async def test_full_ingest_pipeline(self):
        """å®Œæ•´å…¥åº“æµç¨‹: æ–‡ä»¶ â†’ è§£æ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ å†™å…¥DB"""
        from services.ingest import KnowledgeIngestor

        async with self.SessionLocal() as session:
            ingestor = KnowledgeIngestor(db=session, embedder=self.embedder)
            doc_id = await ingestor.ingest_file(
                self.test_doc_path,
                scope="tenant",
                domain_id="tcm",
                tenant_id="test_tenant",
                author="æµ‹è¯•ä½œè€…",
                source_name="ä¸­åŒ»ä½“è´¨å­¦",
                priority=8,
            )
            self._cleanup_doc_ids.append(doc_id)

            self.assertIsNotNone(doc_id, "å…¥åº“å¤±è´¥! doc_id ä¸º None")
            self.assertGreater(doc_id, 0)

            # éªŒè¯æ•°æ®åº“ä¸­æœ‰ chunks
            from sqlalchemy import text
            row = await session.execute(
                text("SELECT COUNT(*) FROM knowledge_chunks WHERE document_id = :id"),
                {"id": doc_id}
            )
            chunk_count = row.scalar()
            self.assertGreater(chunk_count, 0,
                               f"å…¥åº“å chunk æ•°ä¸º 0! doc_id={doc_id}")
            print(f"  âœ… å…¥åº“æˆåŠŸ: doc_id={doc_id}, {chunk_count} chunks")

    async def test_ingest_dedup(self):
        """é‡å¤å…¥åº“åº”å»é‡ (ç›¸åŒæ–‡ä»¶å“ˆå¸Œ)"""
        from services.ingest import KnowledgeIngestor

        async with self.SessionLocal() as session:
            ingestor = KnowledgeIngestor(db=session, embedder=self.embedder)

            # ç¬¬ä¸€æ¬¡å…¥åº“
            doc_id1 = await ingestor.ingest_file(
                self.test_doc_path, scope="platform", domain_id="tcm",
            )
            self._cleanup_doc_ids.append(doc_id1)

            # ç¬¬äºŒæ¬¡å…¥åº“åŒä¸€æ–‡ä»¶
            doc_id2 = await ingestor.ingest_file(
                self.test_doc_path, scope="platform", domain_id="tcm",
            )
            if doc_id2 and doc_id2 != doc_id1:
                self._cleanup_doc_ids.append(doc_id2)

            # åº”è¿”å›ç›¸åŒ doc_id æˆ–è·³è¿‡
            # (å…·ä½“è¡Œä¸ºå–å†³äºå®ç°: è¿”å›å·²æœ‰ ID æˆ–æŠ›å¼‚å¸¸)
            print(f"  ç¬¬ä¸€æ¬¡: {doc_id1}, ç¬¬äºŒæ¬¡: {doc_id2}")
            if doc_id2 is not None:
                self.assertEqual(doc_id1, doc_id2,
                                 "é‡å¤å…¥åº“åº”è¿”å›å·²æœ‰ doc_id æˆ–è·³è¿‡!")

    async def test_vector_search_after_ingest(self):
        """å…¥åº“åå‘é‡æ£€ç´¢èƒ½æ‰¾åˆ°æ–‡æ¡£"""
        from services.ingest import KnowledgeIngestor
        from sqlalchemy import text

        async with self.SessionLocal() as session:
            ingestor = KnowledgeIngestor(db=session, embedder=self.embedder)
            doc_id = await ingestor.ingest_file(
                self.test_doc_path, scope="domain", domain_id="tcm",
                author="æµ‹è¯•", priority=5,
            )
            self._cleanup_doc_ids.append(doc_id)

            # ç”¨è¯­ä¹‰æ£€ç´¢æŸ¥æ‰¾
            query_vec = self.embedder.embed("æ°”è™šä½“è´¨è°ƒç†æ–¹æ³•")
            vec_str = str(query_vec)

            row = await session.execute(text(f"""
                SELECT c.content, c.heading, c.scope,
                       1.0 - (c.embedding <=> '{vec_str}'::vector(768)) AS score
                FROM knowledge_chunks c
                WHERE c.document_id = :doc_id
                ORDER BY score DESC
                LIMIT 3
            """), {"doc_id": doc_id})
            results = row.fetchall()

            self.assertTrue(len(results) > 0, "å‘é‡æ£€ç´¢æœªè¿”å›ç»“æœ!")

            # æœ€ç›¸å…³çš„ç»“æœåº”åŒ…å«"æ°”è™š"ç›¸å…³å†…å®¹
            top_content = results[0][0]
            top_score = results[0][3]
            print(f"  âœ… æ£€ç´¢åˆ° {len(results)} æ¡, Top score={top_score:.3f}")
            print(f"     Top content: {top_content[:60]}...")

            self.assertGreater(top_score, 0.3,
                               f"æœ€ä½³åŒ¹é…åˆ†æ•°è¿‡ä½: {top_score:.3f}")

    async def test_scope_priority_ordering(self):
        """RAG v2 æ ¸å¿ƒ: scope ä¼˜å…ˆçº§æ’åº (tenant > domain > platform)"""
        from services.ingest import KnowledgeIngestor
        from sqlalchemy import text
        import tempfile

        async with self.SessionLocal() as session:
            ingestor = KnowledgeIngestor(db=session, embedder=self.embedder)

            # 3 ä¸ªä¸åŒæ–‡ä»¶ (ä¸åŒhash), ç›¸ä¼¼å†…å®¹, å…¥åº“åˆ°ä¸åŒ scope
            scopes_config = [
                ("platform", "", 5, "ä½“è´¨è¾¨è¯†æ˜¯ä¸­åŒ»åŸºç¡€ç†è®º (å¹³å°ç‰ˆ)"),
                ("domain", "", 5, "ä½“è´¨è¾¨è¯†æ˜¯ä¸­åŒ»åŸºç¡€ç†è®º (é¢†åŸŸç‰ˆ)"),
                ("tenant", "test_tenant", 5, "ä½“è´¨è¾¨è¯†æ˜¯ä¸­åŒ»åŸºç¡€ç†è®º (ä¸“å®¶ç‰ˆ)"),
            ]

            for scope, tenant_id, priority, content in scopes_config:
                # æ¯ä¸ª scope ç”¨ç‹¬ç«‹æ–‡ä»¶ (ä¸åŒ hash é¿å…å»é‡)
                path = os.path.join(self.tmpdir, f"scope_test_{scope}.md")
                with open(path, "w", encoding="utf-8") as f:
                    f.write(f"# ä½“è´¨è¾¨è¯† - {scope}\n\n{content}\n")
                doc_id = await ingestor.ingest_file(
                    path,
                    scope=scope, domain_id="tcm",
                    tenant_id=tenant_id, priority=priority,
                )
                self._cleanup_doc_ids.append(doc_id)

            # ç”¨ RAG v2 çš„åŠ æƒæŸ¥è¯¢
            query_vec = self.embedder.embed("ä½“è´¨è¾¨è¯†")
            vec_str = str(query_vec)

            row = await session.execute(text(f"""
                SELECT c.scope,
                       1.0 - (c.embedding <=> '{vec_str}'::vector(768)) AS raw_score,
                       1.0 - (c.embedding <=> '{vec_str}'::vector(768))
                         + CASE c.scope
                             WHEN 'tenant' THEN 0.15
                             WHEN 'domain' THEN 0.08
                             ELSE 0.0
                           END AS boosted_score
                FROM knowledge_chunks c
                JOIN knowledge_documents d ON d.id = c.document_id
                WHERE d.is_active = true
                  AND d.id IN ({','.join(str(i) for i in self._cleanup_doc_ids)})
                ORDER BY boosted_score DESC
                LIMIT 10
            """))
            results = row.fetchall()
            self.assertTrue(len(results) > 0)

            # ç¬¬ä¸€æ¡åº”ä¸º tenant scope
            self.assertEqual(results[0][0], 'tenant',
                             f"åŠ æƒå tenant åº”æ’ç¬¬ä¸€, å®é™…: {results[0][0]}")
            print(f"  âœ… Scope æ’åºæ­£ç¡®: {[r[0] for r in results[:3]]}")


class TestRAGContextIntegration(unittest.TestCase):
    """RAGContext é›†æˆæµ‹è¯• â€” æ¨¡æ‹Ÿå®Œæ•´ RAG å›å¤å¤„ç†"""

    def test_full_response_processing(self):
        """æ¨¡æ‹Ÿå®Œæ•´ RAG å›å¤è§£ææµç¨‹"""
        from services.retriever import Citation, RAGContext, SourceType

        # æ¨¡æ‹Ÿæ£€ç´¢åˆ°çš„å¼•ç”¨
        citations = [
            Citation(1, "ä¸­åŒ»ä½“è´¨è¾¨è¯†æŒ‡å—", "ä¹ç§ä½“è´¨", "ç‹ç¦", "ä¸­åŒ»æ•™æ", 5,
                     0.92, "ä¸­åŒ»å°†äººä½“ä½“è´¨åˆ†ä¸ºä¹ç§...", 101, 10,
                     "tenant", SourceType.KNOWLEDGE),
            Citation(2, "å¤§äº”äººæ ¼åº”ç”¨", "å¼€æ”¾æ€§", "", "", None,
                     0.78, "é«˜å¼€æ”¾æ€§äººç¾¤...", 201, 20,
                     "domain", SourceType.KNOWLEDGE),
            Citation(3, "å¹³å°å¥åº·æŒ‡å—", "è¿åŠ¨å»ºè®®", "", "å¹³å°èµ„æ–™", None,
                     0.65, "æ¯å¤©è‡³å°‘30åˆ†é’Ÿ...", 301, 30,
                     "platform", SourceType.KNOWLEDGE),
        ]

        ctx = RAGContext(
            query="æ°”è™šä½“è´¨çš„äººå¦‚ä½•é€šè¿‡å¤§äº”äººæ ¼ç‰¹å¾å®šåˆ¶å¥åº·æ–¹æ¡ˆ",
            citations=citations,
            prompt_injection="[æ¨¡æ‹Ÿçš„promptæ³¨å…¥]",
            domains_searched=["tcm", "big_five"],
        )

        # æ¨¡æ‹Ÿ LLM å›å¤ (åŒ…å«å¼•ç”¨å’Œæ¨¡å‹è¡¥å……)
        llm_response = """æ ¹æ®[1]æ‰€è¿°ï¼Œä¸­åŒ»å°†äººä½“ä½“è´¨åˆ†ä¸ºä¹ç§åŸºæœ¬ç±»å‹ï¼Œå…¶ä¸­æ°”è™šè´¨çš„ç‰¹ç‚¹æ˜¯å®¹æ˜“ç–²ä¹ã€æ°”çŸ­ã€è‡ªæ±—ã€‚

é’ˆå¯¹æ°”è™šä½“è´¨çš„è°ƒç†ï¼Œ[1]å»ºè®®è¡¥æ°”ä¸ºä¸»ï¼Œé€‚å®œé£Ÿç”¨é»„èŠªã€å…šå‚ç­‰è¡¥æ°”é£Ÿæï¼Œé¿å…è¿‡åº¦åŠ³ç´¯ã€‚

åœ¨å¥åº·æ–¹æ¡ˆå®šåˆ¶æ–¹é¢ï¼Œ[2]æŒ‡å‡ºé«˜å¼€æ”¾æ€§äººç¾¤å¯¹åˆ›æ–°æ–¹æ¡ˆæ¥å—åº¦è¾ƒé«˜ï¼Œå¯ä»¥å¼•å…¥å¤šæ ·åŒ–çš„è°ƒç†é€‰æ‹©ã€‚ç»“åˆ[3]çš„è¿åŠ¨å»ºè®®ï¼Œé€‚é‡è¿åŠ¨å¯¹æ°”è™šä½“è´¨å¾ˆé‡è¦ã€‚

ã€è¡¥å……ã€‘ä»ç°ä»£è¥å…»å­¦è§’åº¦æ¥çœ‹ï¼Œæ°”è™šä½“è´¨çš„äººè¿˜åº”æ³¨æ„è›‹ç™½è´¨æ‘„å…¥ï¼Œä¿è¯æ¯æ—¥ä¼˜è´¨è›‹ç™½ä¾›ç»™ã€‚åŒæ—¶ï¼Œé€‚å½“è¡¥å……Bæ—ç»´ç”Ÿç´ å’Œé“å…ƒç´ æœ‰åŠ©äºæ”¹å–„æ°”è™šç—‡çŠ¶ã€‚"""

        result = ctx.format_response(llm_response)

        # â”€â”€ éªŒè¯å®Œæ•´å“åº”ç»“æ„ â”€â”€

        # 1. åŸºæœ¬å­—æ®µ
        self.assertIn("text", result)
        self.assertTrue(result["hasKnowledge"])
        self.assertEqual(result["citationsUsed"], [1, 2, 3])

        # 2. çŸ¥è¯†åº“å¼•ç”¨ (æŒ‰ scope åˆ†ç»„)
        kc = result["knowledgeCitations"]
        self.assertEqual(len(kc), 3)
        scopes = [c["scope"] for c in kc]
        self.assertIn("tenant", scopes)
        self.assertIn("domain", scopes)
        self.assertIn("platform", scopes)

        # 3. æ¨¡å‹è¡¥å……æ£€æµ‹
        self.assertTrue(result["hasModelSupplement"])
        self.assertTrue(len(result["modelSupplementSections"]) > 0)
        self.assertIn("è¥å…»å­¦", result["modelSupplementSections"][0])

        # 4. æ¥æºç»Ÿè®¡
        stats = result["sourceStats"]
        self.assertEqual(stats["knowledgeCount"], 3)
        self.assertTrue(stats["modelSupplement"])
        self.assertEqual(stats["scopeBreakdown"]["tenant"], 1)
        self.assertEqual(stats["scopeBreakdown"]["domain"], 1)
        self.assertEqual(stats["scopeBreakdown"]["platform"], 1)

        print("  âœ… RAG å›å¤è§£æå®Œæ•´")
        print(f"     å¼•ç”¨: {result['citationsUsed']}")
        print(f"     æ¥æºç»Ÿè®¡: {stats}")
        print(f"     æ¨¡å‹è¡¥å……: {len(result['modelSupplementSections'])} æ®µ")

    def test_no_knowledge_response(self):
        """æ— çŸ¥è¯†åº“å‘½ä¸­æ—¶çš„çº¯æ¨¡å‹å›å¤å¤„ç†"""
        from services.retriever import RAGContext

        ctx = RAGContext(
            query="è¯·é—®ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·",
            citations=[], prompt_injection="", domains_searched=[],
        )

        llm_response = "ã€ä»¥ä¸‹ä¸ºé€šç”¨ä¸“ä¸šçŸ¥è¯†ï¼Œéæœ¬å¹³å°ä¸“å±èµ„æ–™ã€‘\næŠ±æ­‰ï¼Œå¤©æ°”æŸ¥è¯¢ä¸åœ¨æœ¬å¹³å°çŸ¥è¯†èŒƒå›´å†…ã€‚"
        result = ctx.format_response(llm_response)

        self.assertFalse(result["hasKnowledge"])
        self.assertEqual(len(result["citationsUsed"]), 0)
        self.assertEqual(len(result["knowledgeCitations"]), 0)

    def test_mixed_citation_and_supplement(self):
        """æ··åˆå¼•ç”¨å’Œè¡¥å……çš„è¾¹ç•Œæƒ…å†µ"""
        from services.retriever import Citation, RAGContext, SourceType

        citations = [
            Citation(1, "æ–‡æ¡£A", "", "", "", None, 0.85, "å†…å®¹A", 1, 1,
                     "tenant", SourceType.KNOWLEDGE),
        ]
        ctx = RAGContext(query="æµ‹è¯•", citations=citations,
                         prompt_injection="", domains_searched=["tcm"])

        # åªç”¨äº† [1]ï¼Œä½†æœ‰ä¸¤å¤„è¡¥å……
        llm_response = "æ ¹æ®[1]çš„èµ„æ–™ã€‚\n\nã€è¡¥å……ã€‘é¢å¤–ä¿¡æ¯1ã€‚\n\nã€æ¨¡å‹è¡¥å……ã€‘é¢å¤–ä¿¡æ¯2ã€‚"
        result = ctx.format_response(llm_response)

        self.assertEqual(result["citationsUsed"], [1])
        self.assertTrue(result["hasModelSupplement"])
        self.assertGreaterEqual(len(result["modelSupplementSections"]), 1)


class TestFrontendDataContract(unittest.TestCase):
    """å‰ç«¯æ•°æ®å¥‘çº¦éªŒè¯ â€” ç¡®ä¿åç«¯è¾“å‡ºåŒ¹é…å‰ç«¯æœŸæœ›"""

    def test_citation_dict_matches_vue_props(self):
        """Citation.to_dict() è¾“å‡ºåŒ¹é… CitationBlock.vue çš„ props"""
        from services.retriever import Citation, SourceType

        c = Citation(1, "æ–‡æ¡£", "ç« èŠ‚", "ä½œè€…", "æ¥æº", 5, 0.9,
                     "é¢„è§ˆ...", 100, 10, "tenant", SourceType.KNOWLEDGE)
        d = c.to_dict()

        # CitationBlock.vue çš„ citation å¯¹è±¡æœŸæœ›å­—æ®µ
        vue_expected = {
            "index", "label", "contentPreview", "relevanceScore",
            "scope", "scopeLabel", "sourceType",
        }
        for key in vue_expected:
            self.assertIn(key, d,
                          f"Citation.to_dict() ç¼ºå°‘å‰ç«¯éœ€è¦çš„å­—æ®µ: {key}")

    def test_format_response_matches_vue_props(self):
        """format_response() è¾“å‡ºåŒ¹é… CitationBlock.vue çš„å®Œæ•´ props"""
        from services.retriever import Citation, RAGContext, SourceType

        citations = [
            Citation(1, "T", "", "", "", None, 0.8, "P", 1, 1,
                     "tenant", SourceType.KNOWLEDGE),
        ]
        ctx = RAGContext("q", citations, "prompt", ["tcm"])
        result = ctx.format_response("å›ç­”[1]ã€‚\n\nã€è¡¥å……ã€‘é¢å¤–ã€‚")

        # CitationBlock.vue v2 æ–°å¢ props
        vue_props = [
            "knowledgeCitations",      # ä»…çŸ¥è¯†åº“å¼•ç”¨
            "hasModelSupplement",      # æ˜¯å¦æœ‰æ¨¡å‹è¡¥å……
            "modelSupplementSections", # æ¨¡å‹è¡¥å……æ®µè½åˆ—è¡¨
            "sourceStats",             # æ¥æºç»Ÿè®¡
        ]
        for prop in vue_props:
            self.assertIn(prop, result,
                          f"format_response ç¼ºå°‘å‰ç«¯ prop: {prop}")

        # sourceStats ç»“æ„
        stats = result["sourceStats"]
        for key in ["knowledgeCount", "modelSupplement", "scopeBreakdown"]:
            self.assertIn(key, stats,
                          f"sourceStats ç¼ºå°‘å­—æ®µ: {key}")

    def test_scope_label_format(self):
        """scope æ ‡ç­¾æ ¼å¼ä¸ CitationBlock.vue æ ·å¼ä¸€è‡´"""
        from services.retriever import Citation, SourceType

        expected_labels = {
            "tenant": "ğŸ”’ ä¸“å®¶ç§æœ‰",
            "domain": "ğŸ“‚ é¢†åŸŸçŸ¥è¯†",
            "platform": "ğŸŒ å¹³å°å…¬å…±",
        }
        for scope, label in expected_labels.items():
            c = Citation(1, "T", "", "", "", None, 0.5, "", 1, 1,
                         scope, SourceType.KNOWLEDGE)
            self.assertEqual(c.scope_label, label,
                             f"scope={scope} æ ‡ç­¾ä¸åŒ¹é…å‰ç«¯é¢„æœŸ")


if __name__ == '__main__':
    unittest.main(verbosity=2)
